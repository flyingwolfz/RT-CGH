//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-26907403
// Cuda compilation tools, release 10.1, V10.1.243
// Based on LLVM 3.4svn
//

.version 6.4
.target sm_35
.address_size 64

	// .globl	_Z14pinhole_camerav
.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
.global .align 4 .b8 eye[12];
.global .align 4 .b8 U[12];
.global .align 4 .b8 V[12];
.global .align 4 .b8 W[12];
.global .align 4 .b8 bad_color[12];
.global .align 4 .b8 bg_color[12];
.global .align 4 .f32 scene_epsilon;
.global .align 4 .f32 z;
.global .align 4 .f32 juli;
.global .align 1 .b8 output_buffer[1];
.global .align 4 .b8 top_object[4];
.global .align 4 .f32 t_hit;
.global .align 8 .b8 launch_index[8];
.global .align 8 .b8 launch_dim[8];
.global .align 4 .b8 shading_normal[12];
.global .align 4 .b8 prd_radiance[16];
.global .align 4 .b8 ray[36];
.global .align 4 .b8 l1[12];
.global .align 4 .f32 fencengshu;
.global .align 4 .f32 maxextent;
.global .align 4 .f32 len;
.global .align 1 .b8 random[1];
.global .align 1 .b8 complex[1];
.global .align 4 .b8 Ka[12];
.global .align 4 .b8 Kd[12];
.global .align 4 .b8 ambient_light_color[12];
.global .align 1 .b8 lights[1];
.global .align 4 .b8 _ZN21rti_internal_typeinfo3eyeE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo1UE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo1VE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo1WE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo9bad_colorE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo8bg_colorE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo13scene_epsilonE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo1zE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo4juliE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo10top_objectE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo5t_hitE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo12launch_indexE[8] = {82, 97, 121, 0, 8, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo10launch_dimE[8] = {82, 97, 121, 0, 8, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo14shading_normalE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo12prd_radianceE[8] = {82, 97, 121, 0, 16, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo3rayE[8] = {82, 97, 121, 0, 36, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo2l1E[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo10fencengshuE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo9maxextentE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo3lenE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo2KaE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo2KdE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo19ambient_light_colorE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 8 .u64 _ZN21rti_internal_register20reg_bitness_detectorE;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail0E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail1E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail2E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail3E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail4E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail5E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail6E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail7E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail8E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail9E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail0E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail1E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail2E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail3E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail4E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail5E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail6E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail7E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail8E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail9E;
.global .align 4 .u32 _ZN21rti_internal_register14reg_rayIndex_xE;
.global .align 4 .u32 _ZN21rti_internal_register14reg_rayIndex_yE;
.global .align 4 .u32 _ZN21rti_internal_register14reg_rayIndex_zE;
.global .align 1 .b8 _ZN21rti_internal_typename3eyeE[7] = {102, 108, 111, 97, 116, 51, 0};
.global .align 1 .b8 _ZN21rti_internal_typename1UE[7] = {102, 108, 111, 97, 116, 51, 0};
.global .align 1 .b8 _ZN21rti_internal_typename1VE[7] = {102, 108, 111, 97, 116, 51, 0};
.global .align 1 .b8 _ZN21rti_internal_typename1WE[7] = {102, 108, 111, 97, 116, 51, 0};
.global .align 1 .b8 _ZN21rti_internal_typename9bad_colorE[7] = {102, 108, 111, 97, 116, 51, 0};
.global .align 1 .b8 _ZN21rti_internal_typename8bg_colorE[7] = {102, 108, 111, 97, 116, 51, 0};
.global .align 1 .b8 _ZN21rti_internal_typename13scene_epsilonE[6] = {102, 108, 111, 97, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename1zE[6] = {102, 108, 111, 97, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename4juliE[6] = {102, 108, 111, 97, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename10top_objectE[9] = {114, 116, 79, 98, 106, 101, 99, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename5t_hitE[6] = {102, 108, 111, 97, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename12launch_indexE[6] = {117, 105, 110, 116, 50, 0};
.global .align 1 .b8 _ZN21rti_internal_typename10launch_dimE[6] = {117, 105, 110, 116, 50, 0};
.global .align 1 .b8 _ZN21rti_internal_typename14shading_normalE[7] = {102, 108, 111, 97, 116, 51, 0};
.global .align 1 .b8 _ZN21rti_internal_typename12prd_radianceE[20] = {80, 101, 114, 82, 97, 121, 68, 97, 116, 97, 95, 114, 97, 100, 105, 97, 110, 99, 101, 0};
.global .align 1 .b8 _ZN21rti_internal_typename3rayE[11] = {111, 112, 116, 105, 120, 58, 58, 82, 97, 121, 0};
.global .align 1 .b8 _ZN21rti_internal_typename2l1E[7] = {102, 108, 111, 97, 116, 51, 0};
.global .align 1 .b8 _ZN21rti_internal_typename10fencengshuE[6] = {102, 108, 111, 97, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename9maxextentE[6] = {102, 108, 111, 97, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename3lenE[6] = {102, 108, 111, 97, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename2KaE[7] = {102, 108, 111, 97, 116, 51, 0};
.global .align 1 .b8 _ZN21rti_internal_typename2KdE[7] = {102, 108, 111, 97, 116, 51, 0};
.global .align 1 .b8 _ZN21rti_internal_typename19ambient_light_colorE[7] = {102, 108, 111, 97, 116, 51, 0};
.global .align 4 .u32 _ZN21rti_internal_typeenum3eyeE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum1UE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum1VE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum1WE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum9bad_colorE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum8bg_colorE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum13scene_epsilonE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum1zE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum4juliE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum10top_objectE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum5t_hitE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum12launch_indexE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum10launch_dimE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum14shading_normalE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum12prd_radianceE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum3rayE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum2l1E = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum10fencengshuE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum9maxextentE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum3lenE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum2KaE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum2KdE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum19ambient_light_colorE = 4919;
.global .align 1 .b8 _ZN21rti_internal_semantic3eyeE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic1UE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic1VE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic1WE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic9bad_colorE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic8bg_colorE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic13scene_epsilonE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic1zE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic4juliE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic10top_objectE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic5t_hitE[23] = {114, 116, 73, 110, 116, 101, 114, 115, 101, 99, 116, 105, 111, 110, 68, 105, 115, 116, 97, 110, 99, 101, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic12launch_indexE[14] = {114, 116, 76, 97, 117, 110, 99, 104, 73, 110, 100, 101, 120, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic10launch_dimE[12] = {114, 116, 76, 97, 117, 110, 99, 104, 68, 105, 109, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic14shading_normalE[25] = {97, 116, 116, 114, 105, 98, 117, 116, 101, 32, 115, 104, 97, 100, 105, 110, 103, 95, 110, 111, 114, 109, 97, 108, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic12prd_radianceE[10] = {114, 116, 80, 97, 121, 108, 111, 97, 100, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic3rayE[13] = {114, 116, 67, 117, 114, 114, 101, 110, 116, 82, 97, 121, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic2l1E[1];
.global .align 1 .b8 _ZN21rti_internal_semantic10fencengshuE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic9maxextentE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic3lenE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic2KaE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic2KdE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic19ambient_light_colorE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation3eyeE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation1UE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation1VE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation1WE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation9bad_colorE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation8bg_colorE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation13scene_epsilonE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation1zE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation4juliE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation10top_objectE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation5t_hitE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation12launch_indexE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation10launch_dimE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation14shading_normalE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation12prd_radianceE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation3rayE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation2l1E[1];
.global .align 1 .b8 _ZN23rti_internal_annotation10fencengshuE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation9maxextentE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation3lenE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation2KaE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation2KdE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation19ambient_light_colorE[1];
.global .align 1 .b8 $str[64] = {67, 97, 117, 103, 104, 116, 32, 82, 84, 95, 69, 88, 67, 69, 80, 84, 73, 79, 78, 95, 83, 84, 65, 67, 75, 95, 79, 86, 69, 82, 70, 76, 79, 87, 10, 32, 32, 108, 97, 117, 110, 99, 104, 32, 105, 110, 100, 101, 120, 32, 58, 32, 37, 100, 44, 32, 37, 100, 44, 32, 37, 100, 10, 0};
.global .align 1 .b8 $str1[70] = {67, 97, 117, 103, 104, 116, 32, 82, 84, 95, 69, 88, 67, 69, 80, 84, 73, 79, 78, 95, 84, 82, 65, 67, 69, 95, 68, 69, 80, 84, 72, 95, 69, 88, 67, 69, 69, 68, 69, 68, 10, 32, 32, 108, 97, 117, 110, 99, 104, 32, 105, 110, 100, 101, 120, 32, 58, 32, 37, 100, 44, 32, 37, 100, 44, 32, 37, 100, 10, 0};
.global .align 1 .b8 $str2[236] = {67, 97, 117, 103, 104, 116, 32, 82, 84, 95, 69, 88, 67, 69, 80, 84, 73, 79, 78, 95, 66, 85, 70, 70, 69, 82, 95, 73, 78, 68, 69, 88, 95, 79, 85, 84, 95, 79, 70, 95, 66, 79, 85, 78, 68, 83, 10, 32, 32, 108, 97, 117, 110, 99, 104, 32, 105, 110, 100, 101, 120, 32, 32, 32, 58, 32, 37, 100, 44, 32, 37, 100, 44, 32, 37, 100, 10, 32, 32, 100, 105, 109, 101, 110, 115, 105, 111, 110, 97, 108, 105, 116, 121, 32, 58, 32, 37, 100, 10, 32, 32, 98, 117, 102, 102, 101, 114, 32, 100, 101, 116, 97, 105, 108, 115, 32, 58, 32, 37, 115, 10, 32, 32, 98, 117, 102, 102, 101, 114, 32, 73, 68, 32, 32, 32, 32, 32, 32, 58, 32, 37, 100, 10, 32, 32, 115, 105, 122, 101, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 58, 32, 37, 108, 108, 100, 120, 37, 108, 108, 100, 120, 37, 108, 108, 100, 10, 32, 32, 101, 108, 101, 109, 101, 110, 116, 32, 115, 105, 122, 101, 32, 32, 32, 58, 32, 37, 100, 10, 32, 32, 97, 99, 99, 101, 115, 115, 101, 100, 32, 105, 110, 100, 101, 120, 32, 58, 32, 37, 108, 108, 100, 44, 32, 37, 108, 108, 100, 44, 32, 37, 108, 108, 100, 10, 0};
.global .align 1 .b8 $str3[138] = {67, 97, 117, 103, 104, 116, 32, 82, 84, 95, 69, 88, 67, 69, 80, 84, 73, 79, 78, 95, 80, 82, 79, 71, 82, 65, 77, 95, 73, 68, 95, 73, 78, 86, 65, 76, 73, 68, 10, 32, 32, 112, 114, 111, 103, 114, 97, 109, 32, 73, 68, 32, 101, 113, 117, 97, 108, 32, 116, 111, 32, 82, 84, 95, 80, 82, 79, 71, 82, 65, 77, 95, 73, 68, 95, 78, 85, 76, 76, 32, 117, 115, 101, 100, 10, 32, 32, 108, 97, 117, 110, 99, 104, 32, 105, 110, 100, 101, 120, 32, 32, 32, 58, 32, 37, 100, 44, 32, 37, 100, 44, 32, 37, 100, 10, 32, 32, 108, 111, 99, 97, 116, 105, 111, 110, 32, 32, 32, 32, 32, 32, 32, 58, 32, 37, 115, 10, 0};
.global .align 1 .b8 $str4[148] = {67, 97, 117, 103, 104, 116, 32, 82, 84, 95, 69, 88, 67, 69, 80, 84, 73, 79, 78, 95, 80, 82, 79, 71, 82, 65, 77, 95, 73, 68, 95, 73, 78, 86, 65, 76, 73, 68, 10, 32, 32, 112, 114, 111, 103, 114, 97, 109, 32, 73, 68, 32, 40, 37, 100, 41, 32, 105, 115, 32, 110, 111, 116, 32, 105, 110, 32, 116, 104, 101, 32, 118, 97, 108, 105, 100, 32, 114, 97, 110, 103, 101, 32, 111, 102, 32, 91, 49, 44, 115, 105, 122, 101, 41, 10, 32, 32, 108, 97, 117, 110, 99, 104, 32, 105, 110, 100, 101, 120, 32, 32, 32, 58, 32, 37, 100, 44, 32, 37, 100, 44, 32, 37, 100, 10, 32, 32, 108, 111, 99, 97, 116, 105, 111, 110, 32, 32, 32, 32, 32, 32, 32, 58, 32, 37, 115, 10, 0};
.global .align 1 .b8 $str5[136] = {67, 97, 117, 103, 104, 116, 32, 82, 84, 95, 69, 88, 67, 69, 80, 84, 73, 79, 78, 95, 80, 82, 79, 71, 82, 65, 77, 95, 73, 68, 95, 73, 78, 86, 65, 76, 73, 68, 10, 32, 32, 112, 114, 111, 103, 114, 97, 109, 32, 73, 68, 32, 40, 37, 100, 41, 32, 111, 102, 32, 97, 32, 100, 101, 108, 101, 116, 101, 100, 32, 112, 114, 111, 103, 114, 97, 109, 32, 117, 115, 101, 100, 10, 32, 32, 108, 97, 117, 110, 99, 104, 32, 105, 110, 100, 101, 120, 32, 32, 32, 58, 32, 37, 100, 44, 32, 37, 100, 44, 32, 37, 100, 10, 32, 32, 108, 111, 99, 97, 116, 105, 111, 110, 32, 32, 32, 32, 32, 32, 32, 58, 32, 37, 115, 10, 0};
.global .align 1 .b8 $str6[98] = {67, 97, 117, 103, 104, 116, 32, 82, 84, 95, 69, 88, 67, 69, 80, 84, 73, 79, 78, 95, 84, 69, 88, 84, 85, 82, 69, 95, 73, 68, 95, 73, 78, 86, 65, 76, 73, 68, 10, 32, 32, 116, 101, 120, 116, 117, 114, 101, 32, 73, 68, 32, 105, 115, 32, 105, 110, 118, 97, 108, 105, 100, 32, 40, 48, 41, 10, 32, 32, 108, 97, 117, 110, 99, 104, 32, 105, 110, 100, 101, 120, 32, 32, 32, 58, 32, 37, 100, 44, 32, 37, 100, 44, 32, 37, 100, 10, 0};
.global .align 1 .b8 $str7[126] = {67, 97, 117, 103, 104, 116, 32, 82, 84, 95, 69, 88, 67, 69, 80, 84, 73, 79, 78, 95, 84, 69, 88, 84, 85, 82, 69, 95, 73, 68, 95, 73, 78, 86, 65, 76, 73, 68, 10, 32, 32, 116, 101, 120, 116, 117, 114, 101, 32, 73, 68, 32, 40, 37, 100, 41, 32, 105, 115, 32, 110, 111, 116, 32, 105, 110, 32, 116, 104, 101, 32, 118, 97, 108, 105, 100, 32, 114, 97, 110, 103, 101, 32, 111, 102, 32, 91, 49, 44, 115, 105, 122, 101, 41, 10, 32, 32, 108, 97, 117, 110, 99, 104, 32, 105, 110, 100, 101, 120, 32, 32, 32, 58, 32, 37, 100, 44, 32, 37, 100, 44, 32, 37, 100, 10, 0};
.global .align 1 .b8 $str8[99] = {67, 97, 117, 103, 104, 116, 32, 82, 84, 95, 69, 88, 67, 69, 80, 84, 73, 79, 78, 95, 84, 69, 88, 84, 85, 82, 69, 95, 73, 68, 95, 73, 78, 86, 65, 76, 73, 68, 10, 32, 32, 116, 101, 120, 116, 117, 114, 101, 32, 73, 68, 32, 105, 115, 32, 105, 110, 118, 97, 108, 105, 100, 32, 40, 45, 49, 41, 10, 32, 32, 108, 97, 117, 110, 99, 104, 32, 105, 110, 100, 101, 120, 32, 32, 32, 58, 32, 37, 100, 44, 32, 37, 100, 44, 32, 37, 100, 10, 0};
.global .align 1 .b8 $str9[135] = {67, 97, 117, 103, 104, 116, 32, 82, 84, 95, 69, 88, 67, 69, 80, 84, 73, 79, 78, 95, 66, 85, 70, 70, 69, 82, 95, 73, 68, 95, 73, 78, 86, 65, 76, 73, 68, 10, 32, 32, 98, 117, 102, 102, 101, 114, 32, 73, 68, 32, 101, 113, 117, 97, 108, 32, 116, 111, 32, 82, 84, 95, 66, 85, 70, 70, 69, 82, 95, 73, 68, 95, 78, 85, 76, 76, 32, 117, 115, 101, 100, 10, 32, 32, 108, 97, 117, 110, 99, 104, 32, 105, 110, 100, 101, 120, 32, 32, 32, 58, 32, 37, 100, 44, 32, 37, 100, 44, 32, 37, 100, 10, 32, 32, 108, 111, 99, 97, 116, 105, 111, 110, 32, 32, 32, 32, 32, 32, 32, 58, 32, 37, 115, 10, 0};
.global .align 1 .b8 $str10[94] = {67, 97, 117, 103, 104, 116, 32, 82, 84, 95, 69, 88, 67, 69, 80, 84, 73, 79, 78, 95, 66, 85, 70, 70, 69, 82, 95, 73, 68, 95, 73, 78, 86, 65, 76, 73, 68, 10, 32, 32, 98, 117, 102, 102, 101, 114, 32, 73, 68, 32, 40, 37, 100, 41, 32, 105, 115, 32, 110, 111, 116, 32, 105, 110, 32, 116, 104, 101, 32, 118, 97, 108, 105, 100, 32, 114, 97, 110, 103, 101, 32, 111, 102, 32, 91, 49, 44, 115, 105, 122, 101, 41, 10, 0};
.global .align 1 .b8 $str11[53] = {32, 32, 108, 97, 117, 110, 99, 104, 32, 105, 110, 100, 101, 120, 32, 32, 32, 58, 32, 37, 100, 44, 32, 37, 100, 44, 32, 37, 100, 10, 32, 32, 108, 111, 99, 97, 116, 105, 111, 110, 32, 32, 32, 32, 32, 32, 32, 58, 32, 37, 115, 10, 0};
.global .align 1 .b8 $str12[133] = {67, 97, 117, 103, 104, 116, 32, 82, 84, 95, 69, 88, 67, 69, 80, 84, 73, 79, 78, 95, 66, 85, 70, 70, 69, 82, 95, 73, 68, 95, 73, 78, 86, 65, 76, 73, 68, 10, 32, 32, 98, 117, 102, 102, 101, 114, 32, 73, 68, 32, 40, 37, 100, 41, 32, 111, 102, 32, 97, 32, 100, 101, 108, 101, 116, 101, 100, 32, 98, 117, 102, 102, 101, 114, 32, 117, 115, 101, 100, 10, 32, 32, 108, 97, 117, 110, 99, 104, 32, 105, 110, 100, 101, 120, 32, 32, 32, 58, 32, 37, 100, 44, 32, 37, 100, 44, 32, 37, 100, 10, 32, 32, 108, 111, 99, 97, 116, 105, 111, 110, 32, 32, 32, 32, 32, 32, 32, 58, 32, 37, 115, 10, 0};
.global .align 1 .b8 $str13[141] = {67, 97, 117, 103, 104, 116, 32, 82, 84, 95, 69, 88, 67, 69, 80, 84, 73, 79, 78, 95, 73, 78, 68, 69, 88, 95, 79, 85, 84, 95, 79, 70, 95, 66, 79, 85, 78, 68, 83, 10, 32, 32, 108, 97, 117, 110, 99, 104, 32, 105, 110, 100, 101, 120, 32, 32, 32, 58, 32, 37, 100, 44, 32, 37, 100, 44, 32, 37, 100, 10, 32, 32, 108, 111, 99, 97, 116, 105, 111, 110, 32, 32, 32, 32, 32, 32, 32, 58, 32, 37, 115, 10, 32, 32, 115, 105, 122, 101, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 58, 32, 37, 108, 108, 100, 10, 32, 32, 97, 99, 99, 101, 115, 115, 101, 100, 32, 105, 110, 100, 101, 120, 32, 58, 32, 37, 108, 108, 100, 10, 0};
.global .align 1 .b8 $str14[200] = {67, 97, 117, 103, 104, 116, 32, 82, 84, 95, 69, 88, 67, 69, 80, 84, 73, 79, 78, 95, 73, 78, 86, 65, 76, 73, 68, 95, 82, 65, 89, 10, 32, 32, 108, 97, 117, 110, 99, 104, 32, 105, 110, 100, 101, 120, 32, 32, 58, 32, 37, 100, 44, 32, 37, 100, 44, 32, 37, 100, 10, 32, 32, 108, 111, 99, 97, 116, 105, 111, 110, 32, 32, 32, 32, 32, 32, 58, 32, 37, 115, 10, 32, 32, 114, 97, 121, 32, 111, 114, 105, 103, 105, 110, 32, 32, 32, 32, 58, 32, 37, 102, 32, 37, 102, 32, 37, 102, 10, 32, 32, 114, 97, 121, 32, 100, 105, 114, 101, 99, 116, 105, 111, 110, 32, 58, 32, 37, 102, 32, 37, 102, 32, 37, 102, 10, 32, 32, 114, 97, 121, 32, 116, 121, 112, 101, 32, 32, 32, 32, 32, 32, 58, 32, 37, 100, 10, 32, 32, 114, 97, 121, 32, 116, 109, 105, 110, 32, 32, 32, 32, 32, 32, 58, 32, 37, 102, 10, 32, 32, 114, 97, 121, 32, 116, 109, 97, 120, 32, 32, 32, 32, 32, 32, 58, 32, 37, 102, 10, 0};
.global .align 1 .b8 $str15[164] = {67, 97, 117, 103, 104, 116, 32, 82, 84, 95, 69, 88, 67, 69, 80, 84, 73, 79, 78, 95, 80, 65, 89, 76, 79, 65, 68, 95, 65, 67, 67, 69, 83, 83, 95, 79, 85, 84, 95, 79, 70, 95, 66, 79, 85, 78, 68, 83, 10, 32, 32, 108, 97, 117, 110, 99, 104, 32, 105, 110, 100, 101, 120, 32, 58, 32, 37, 100, 44, 32, 37, 100, 44, 32, 37, 100, 10, 32, 32, 108, 111, 99, 97, 116, 105, 111, 110, 32, 32, 32, 32, 32, 58, 32, 37, 115, 10, 32, 32, 118, 97, 108, 117, 101, 32, 111, 102, 102, 115, 101, 116, 32, 58, 32, 37, 108, 108, 100, 10, 32, 32, 118, 97, 108, 117, 101, 32, 115, 105, 122, 101, 32, 32, 32, 58, 32, 37, 108, 108, 100, 10, 32, 32, 112, 97, 121, 108, 111, 97, 100, 32, 115, 105, 122, 101, 32, 58, 32, 37, 108, 108, 100, 10, 0};
.global .align 1 .b8 $str16[123] = {67, 97, 117, 103, 104, 116, 32, 82, 84, 95, 69, 88, 67, 69, 80, 84, 73, 79, 78, 95, 85, 83, 69, 82, 95, 69, 88, 67, 69, 80, 84, 73, 79, 78, 95, 67, 79, 68, 69, 95, 79, 85, 84, 95, 79, 70, 95, 66, 79, 85, 78, 68, 83, 10, 32, 32, 108, 97, 117, 110, 99, 104, 32, 105, 110, 100, 101, 120, 32, 58, 32, 37, 100, 44, 32, 37, 100, 44, 32, 37, 100, 10, 32, 32, 108, 111, 99, 97, 116, 105, 111, 110, 32, 32, 32, 32, 32, 58, 32, 37, 115, 10, 32, 32, 99, 111, 100, 101, 32, 32, 32, 32, 32, 32, 32, 32, 32, 58, 32, 37, 100, 10, 0};
.global .align 1 .b8 $str17[57] = {67, 97, 117, 103, 104, 116, 32, 82, 84, 95, 69, 88, 67, 69, 80, 84, 73, 79, 78, 95, 85, 83, 69, 82, 43, 37, 100, 10, 32, 32, 108, 97, 117, 110, 99, 104, 32, 105, 110, 100, 101, 120, 32, 58, 32, 37, 100, 44, 32, 37, 100, 44, 32, 37, 100, 10, 0};
.global .align 1 .b8 $str18[64] = {67, 97, 117, 103, 104, 116, 32, 82, 84, 95, 69, 88, 67, 69, 80, 84, 73, 79, 78, 95, 73, 78, 84, 69, 82, 78, 65, 76, 95, 69, 82, 82, 79, 82, 10, 32, 32, 108, 97, 117, 110, 99, 104, 32, 105, 110, 100, 101, 120, 32, 58, 32, 37, 100, 44, 32, 37, 100, 44, 32, 37, 100, 10, 0};
.global .align 1 .b8 $str19[54] = {67, 97, 117, 103, 104, 116, 32, 117, 110, 107, 110, 111, 119, 110, 32, 101, 120, 99, 101, 112, 116, 105, 111, 110, 10, 32, 32, 108, 97, 117, 110, 99, 104, 32, 105, 110, 100, 101, 120, 32, 58, 32, 37, 100, 44, 32, 37, 100, 44, 32, 37, 100, 10, 0};
.const .align 4 .b8 __cudart_i2opi_f[24] = {65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};

.visible .entry _Z14pinhole_camerav(

)
{
	.local .align 4 .b8 	__local_depot0[44];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<30>;
	.reg .f32 	%f<169>;
	.reg .b32 	%r<224>;
	.reg .f64 	%fd<19>;
	.reg .b64 	%rd<54>;


	mov.u64 	%SPL, __local_depot0;
	cvta.local.u64 	%SP, %SPL;
	ld.global.v2.u32 	{%r79, %r80}, [launch_index];
	mov.u32 	%r215, 0;
	cvt.rn.f32.u32	%f49, %r79;
	cvt.rn.f32.u32	%f50, %r80;
	ld.global.v2.u32 	{%r83, %r84}, [launch_dim];
	cvt.rn.f32.u32	%f51, %r83;
	cvt.rn.f32.u32	%f52, %r84;
	div.rn.f32 	%f53, %f49, %f51;
	div.rn.f32 	%f54, %f50, %f52;
	fma.rn.f32 	%f55, %f53, 0f40000000, 0fBF800000;
	fma.rn.f32 	%f56, %f54, 0f40000000, 0fBF800000;
	ld.global.f32 	%f41, [eye];
	ld.global.f32 	%f42, [eye+4];
	ld.global.f32 	%f43, [eye+8];
	ld.global.f32 	%f57, [U];
	ld.global.f32 	%f58, [U+4];
	ld.global.f32 	%f59, [U+8];
	ld.global.f32 	%f60, [V];
	mul.f32 	%f61, %f56, %f60;
	ld.global.f32 	%f62, [V+4];
	mul.f32 	%f63, %f56, %f62;
	ld.global.f32 	%f64, [V+8];
	mul.f32 	%f65, %f56, %f64;
	fma.rn.f32 	%f66, %f55, %f57, %f61;
	fma.rn.f32 	%f67, %f55, %f58, %f63;
	fma.rn.f32 	%f68, %f55, %f59, %f65;
	ld.global.f32 	%f69, [W];
	add.f32 	%f70, %f66, %f69;
	ld.global.f32 	%f71, [W+4];
	add.f32 	%f72, %f67, %f71;
	ld.global.f32 	%f73, [W+8];
	add.f32 	%f74, %f68, %f73;
	mul.f32 	%f75, %f72, %f72;
	fma.rn.f32 	%f76, %f70, %f70, %f75;
	fma.rn.f32 	%f77, %f74, %f74, %f76;
	sqrt.rn.f32 	%f78, %f77;
	rcp.rn.f32 	%f79, %f78;
	mul.f32 	%f44, %f70, %f79;
	mul.f32 	%f45, %f72, %f79;
	mul.f32 	%f46, %f74, %f79;
	ld.global.f32 	%f47, [scene_epsilon];
	ld.global.u32 	%r74, [top_object];
	mov.u32 	%r76, 255;
	mov.u32 	%r78, 16;
	mov.f32 	%f48, 0f6C4ECB8F;
	add.u64 	%rd18, %SP, 28;
	// inline asm
	call _rt_trace_mask_flags_64, (%r74, %f41, %f42, %f43, %f44, %f45, %f46, %r215, %f47, %f48, %r76, %r215, %rd18, %r78);
	// inline asm
	ld.global.v2.u32 	{%r87, %r88}, [launch_index];
	cvt.u64.u32	%rd1, %r87;
	cvt.u64.u32	%rd2, %r88;
	ld.global.f32 	%f156, [fencengshu];
	setp.leu.f32	%p1, %f156, 0f00000000;
	@%p1 bra 	BB0_3;

	mov.u32 	%r203, 0;

BB0_2:
	cvt.u64.u32	%rd23, %r203;
	mov.u64 	%rd25, complex;
	cvta.global.u64 	%rd20, %rd25;
	mov.u32 	%r92, 3;
	mov.u32 	%r93, 8;
	mov.u64 	%rd24, 0;
	// inline asm
	call (%rd19), _rt_buffer_get_64, (%rd20, %r92, %r93, %rd1, %rd2, %rd23, %rd24);
	// inline asm
	mov.f32 	%f80, 0f00000000;
	st.v2.f32 	[%rd19], {%f80, %f80};
	add.s32 	%r203, %r203, 1;
	cvt.rn.f32.s32	%f81, %r203;
	ld.global.f32 	%f156, [fencengshu];
	setp.lt.f32	%p2, %f81, %f156;
	@%p2 bra 	BB0_2;

BB0_3:
	cvta.to.local.u64 	%rd27, %rd18;
	add.s64 	%rd3, %rd27, 12;
	ld.local.f32 	%f4, [%rd27+12];
	setp.leu.f32	%p3, %f4, 0f00000000;
	@%p3 bra 	BB0_51;

	ld.global.f32 	%f82, [len];
	sub.f32 	%f83, %f4, %f82;
	ld.global.f32 	%f84, [maxextent];
	fma.rn.f32 	%f85, %f84, 0f3F000000, %f83;
	div.rn.f32 	%f86, %f85, %f84;
	mul.f32 	%f87, %f86, %f156;
	cvt.rmi.f32.f32	%f88, %f87;
	ld.global.f32 	%f89, [juli];
	ld.global.f32 	%f90, [z];
	fma.rn.f32 	%f91, %f88, %f89, %f90;
	cvt.f64.f32	%fd2, %f91;
	mul.f64 	%fd3, %fd2, 0d3F44F0520D130DFA;
	ld.global.v2.u32 	{%r98, %r99}, [launch_dim];
	cvt.rn.f64.u32	%fd4, %r98;
	div.rn.f64 	%fd5, %fd3, %fd4;
	div.rn.f64 	%fd6, %fd5, 0d3F80624DD2F1A9FC;
	cvt.rn.f32.f64	%f92, %fd6;
	cvt.rn.f64.u32	%fd7, %r99;
	div.rn.f64 	%fd8, %fd3, %fd7;
	div.rn.f64 	%fd9, %fd8, 0d3F80624DD2F1A9FC;
	cvt.rn.f32.f64	%f93, %fd9;
	ld.local.f32 	%f94, [%rd3+-12];
	cvt.f64.f32	%fd10, %f94;
	ld.local.f32 	%f95, [%rd3+-8];
	cvt.f64.f32	%fd11, %f95;
	mul.f64 	%fd12, %fd11, 0d3FE2E147AE147AE1;
	fma.rn.f64 	%fd13, %fd10, 0d3FD3333333333333, %fd12;
	ld.local.f32 	%f96, [%rd3+-4];
	cvt.f64.f32	%fd14, %f96;
	fma.rn.f64 	%fd1, %fd14, 0d3FBC28F5C28F5C29, %fd13;
	ld.global.v2.u32 	{%r102, %r103}, [launch_index];
	shr.u32 	%r106, %r98, 1;
	sub.s32 	%r107, %r102, %r106;
	shr.u32 	%r108, %r99, 1;
	sub.s32 	%r109, %r103, %r108;
	mov.f64 	%fd15, 0d40B3346B9BAEE9CE;
	div.rn.f64 	%fd16, %fd15, %fd2;
	cvt.rn.f32.s32	%f97, %r107;
	mul.f32 	%f98, %f92, %f97;
	mul.f32 	%f99, %f97, %f98;
	cvt.rn.f32.s32	%f100, %r109;
	mul.f32 	%f101, %f93, %f100;
	mul.f32 	%f102, %f100, %f101;
	mul.f32 	%f103, %f93, %f102;
	fma.rn.f32 	%f104, %f92, %f99, %f103;
	cvt.u64.u32	%rd30, %r102;
	cvt.u64.u32	%rd31, %r103;
	mov.u64 	%rd40, random;
	cvta.global.u64 	%rd29, %rd40;
	mov.u32 	%r94, 2;
	mov.u32 	%r95, 4;
	mov.u64 	%rd39, 0;
	// inline asm
	call (%rd28), _rt_buffer_get_64, (%rd29, %r94, %r95, %rd30, %rd31, %rd39, %rd39);
	// inline asm
	ld.f32 	%f105, [%rd28];
	add.f32 	%f106, %f105, %f104;
	cvt.f64.f32	%fd17, %f106;
	mul.f64 	%fd18, %fd16, %fd17;
	cvt.rn.f32.f64	%f163, %fd18;
	cvt.rzi.u32.f32	%r110, %f88;
	cvt.u64.u32	%rd38, %r110;
	mov.u64 	%rd41, complex;
	cvta.global.u64 	%rd35, %rd41;
	mov.u32 	%r96, 3;
	mov.u32 	%r97, 8;
	// inline asm
	call (%rd34), _rt_buffer_get_64, (%rd35, %r96, %r97, %rd1, %rd2, %rd38, %rd39);
	// inline asm
	add.u64 	%rd42, %SP, 0;
	add.u64 	%rd5, %SPL, 0;
	abs.f32 	%f6, %f163;
	setp.neu.f32	%p4, %f6, 0f7F800000;
	mov.f32 	%f157, %f163;
	@%p4 bra 	BB0_6;

	mov.f32 	%f107, 0f00000000;
	mul.rn.f32 	%f157, %f163, %f107;

BB0_6:
	mul.f32 	%f108, %f157, 0f3F22F983;
	cvt.rni.s32.f32	%r213, %f108;
	cvt.rn.f32.s32	%f109, %r213;
	neg.f32 	%f110, %f109;
	mov.f32 	%f111, 0f3FC90FDA;
	fma.rn.f32 	%f112, %f110, %f111, %f157;
	mov.f32 	%f113, 0f33A22168;
	fma.rn.f32 	%f114, %f110, %f113, %f112;
	mov.f32 	%f115, 0f27C234C5;
	fma.rn.f32 	%f158, %f110, %f115, %f114;
	abs.f32 	%f116, %f157;
	setp.leu.f32	%p5, %f116, 0f47CE4780;
	@%p5 bra 	BB0_17;

	mov.b32 	 %r4, %f157;
	shr.u32 	%r5, %r4, 23;
	shl.b32 	%r113, %r4, 8;
	or.b32  	%r6, %r113, -2147483648;
	add.s64 	%rd6, %rd5, 24;
	mov.u32 	%r205, 0;
	mov.u64 	%rd50, __cudart_i2opi_f;
	mov.u32 	%r204, -6;
	mov.u64 	%rd51, %rd5;

BB0_8:
	.pragma "nounroll";
	ld.const.u32 	%r116, [%rd50];
	// inline asm
	{
	mad.lo.cc.u32   %r114, %r116, %r6, %r205;
	madc.hi.u32     %r205, %r116, %r6,  0;
	}
	// inline asm
	st.local.u32 	[%rd51], %r114;
	add.s64 	%rd51, %rd51, 4;
	add.s64 	%rd50, %rd50, 4;
	add.s32 	%r204, %r204, 1;
	setp.ne.s32	%p6, %r204, 0;
	@%p6 bra 	BB0_8;

	and.b32  	%r119, %r5, 255;
	add.s32 	%r120, %r119, -128;
	shr.u32 	%r121, %r120, 5;
	and.b32  	%r11, %r4, -2147483648;
	st.local.u32 	[%rd6], %r205;
	mov.u32 	%r122, 6;
	sub.s32 	%r123, %r122, %r121;
	mul.wide.s32 	%rd44, %r123, 4;
	add.s64 	%rd11, %rd5, %rd44;
	ld.local.u32 	%r206, [%rd11];
	ld.local.u32 	%r207, [%rd11+-4];
	and.b32  	%r14, %r5, 31;
	setp.eq.s32	%p7, %r14, 0;
	@%p7 bra 	BB0_11;

	mov.u32 	%r124, 32;
	sub.s32 	%r125, %r124, %r14;
	shr.u32 	%r126, %r207, %r125;
	shl.b32 	%r127, %r206, %r14;
	add.s32 	%r206, %r126, %r127;
	ld.local.u32 	%r128, [%rd11+-8];
	shr.u32 	%r129, %r128, %r125;
	shl.b32 	%r130, %r207, %r14;
	add.s32 	%r207, %r129, %r130;

BB0_11:
	shr.u32 	%r131, %r207, 30;
	shl.b32 	%r132, %r206, 2;
	add.s32 	%r208, %r131, %r132;
	shl.b32 	%r20, %r207, 2;
	shr.u32 	%r133, %r208, 31;
	shr.u32 	%r134, %r206, 30;
	add.s32 	%r21, %r133, %r134;
	setp.eq.s32	%p8, %r133, 0;
	@%p8 bra 	BB0_12;

	not.b32 	%r135, %r208;
	neg.s32 	%r210, %r20;
	setp.eq.s32	%p9, %r20, 0;
	selp.u32	%r136, 1, 0, %p9;
	add.s32 	%r208, %r136, %r135;
	xor.b32  	%r209, %r11, -2147483648;
	bra.uni 	BB0_14;

BB0_12:
	mov.u32 	%r209, %r11;
	mov.u32 	%r210, %r20;

BB0_14:
	clz.b32 	%r212, %r208;
	setp.eq.s32	%p10, %r212, 0;
	shl.b32 	%r137, %r208, %r212;
	mov.u32 	%r138, 32;
	sub.s32 	%r139, %r138, %r212;
	shr.u32 	%r140, %r210, %r139;
	add.s32 	%r141, %r140, %r137;
	selp.b32	%r29, %r208, %r141, %p10;
	mov.u32 	%r142, -921707870;
	mul.hi.u32 	%r211, %r29, %r142;
	setp.eq.s32	%p11, %r11, 0;
	neg.s32 	%r143, %r21;
	selp.b32	%r213, %r21, %r143, %p11;
	setp.lt.s32	%p12, %r211, 1;
	@%p12 bra 	BB0_16;

	mul.lo.s32 	%r144, %r29, -921707870;
	shr.u32 	%r145, %r144, 31;
	shl.b32 	%r146, %r211, 1;
	add.s32 	%r211, %r145, %r146;
	add.s32 	%r212, %r212, 1;

BB0_16:
	mov.u32 	%r147, 126;
	sub.s32 	%r148, %r147, %r212;
	shl.b32 	%r149, %r148, 23;
	add.s32 	%r150, %r211, 1;
	shr.u32 	%r151, %r150, 7;
	add.s32 	%r152, %r151, 1;
	shr.u32 	%r153, %r152, 1;
	add.s32 	%r154, %r153, %r149;
	or.b32  	%r155, %r154, %r209;
	mov.b32 	 %f158, %r155;

BB0_17:
	mul.rn.f32 	%f12, %f158, %f158;
	add.s32 	%r37, %r213, 1;
	and.b32  	%r38, %r37, 1;
	setp.eq.s32	%p13, %r38, 0;
	@%p13 bra 	BB0_19;

	mov.f32 	%f117, 0fBAB6061A;
	mov.f32 	%f118, 0f37CCF5CE;
	fma.rn.f32 	%f159, %f118, %f12, %f117;
	bra.uni 	BB0_20;

BB0_19:
	mov.f32 	%f119, 0f3C08839E;
	mov.f32 	%f120, 0fB94CA1F9;
	fma.rn.f32 	%f159, %f120, %f12, %f119;

BB0_20:
	@%p13 bra 	BB0_22;

	mov.f32 	%f121, 0f3D2AAAA5;
	fma.rn.f32 	%f122, %f159, %f12, %f121;
	mov.f32 	%f123, 0fBF000000;
	fma.rn.f32 	%f160, %f122, %f12, %f123;
	bra.uni 	BB0_23;

BB0_22:
	mov.f32 	%f124, 0fBE2AAAA3;
	fma.rn.f32 	%f125, %f159, %f12, %f124;
	mov.f32 	%f126, 0f00000000;
	fma.rn.f32 	%f160, %f125, %f12, %f126;

BB0_23:
	fma.rn.f32 	%f161, %f160, %f158, %f158;
	@%p13 bra 	BB0_25;

	mov.f32 	%f127, 0f3F800000;
	fma.rn.f32 	%f161, %f160, %f12, %f127;

BB0_25:
	and.b32  	%r156, %r37, 2;
	setp.eq.s32	%p16, %r156, 0;
	@%p16 bra 	BB0_27;

	mov.f32 	%f128, 0f00000000;
	mov.f32 	%f129, 0fBF800000;
	fma.rn.f32 	%f161, %f161, %f129, %f128;

BB0_27:
	@%p4 bra 	BB0_29;

	mov.f32 	%f130, 0f00000000;
	mul.rn.f32 	%f163, %f163, %f130;

BB0_29:
	mul.f32 	%f131, %f163, 0f3F22F983;
	cvt.rni.s32.f32	%r223, %f131;
	cvt.rn.f32.s32	%f132, %r223;
	neg.f32 	%f133, %f132;
	fma.rn.f32 	%f135, %f133, %f111, %f163;
	fma.rn.f32 	%f137, %f133, %f113, %f135;
	fma.rn.f32 	%f164, %f133, %f115, %f137;
	abs.f32 	%f139, %f163;
	setp.leu.f32	%p18, %f139, 0f47CE4780;
	@%p18 bra 	BB0_40;

	mov.b32 	 %r40, %f163;
	shr.u32 	%r41, %r40, 23;
	shl.b32 	%r159, %r40, 8;
	or.b32  	%r42, %r159, -2147483648;
	cvta.to.local.u64 	%rd53, %rd42;
	mov.u64 	%rd52, __cudart_i2opi_f;
	mov.u32 	%r214, -6;

BB0_31:
	.pragma "nounroll";
	ld.const.u32 	%r162, [%rd52];
	// inline asm
	{
	mad.lo.cc.u32   %r160, %r162, %r42, %r215;
	madc.hi.u32     %r215, %r162, %r42,  0;
	}
	// inline asm
	st.local.u32 	[%rd53], %r160;
	add.s64 	%rd53, %rd53, 4;
	add.s64 	%rd52, %rd52, 4;
	add.s32 	%r214, %r214, 1;
	setp.ne.s32	%p19, %r214, 0;
	@%p19 bra 	BB0_31;

	and.b32  	%r165, %r41, 255;
	add.s32 	%r166, %r165, -128;
	shr.u32 	%r167, %r166, 5;
	and.b32  	%r47, %r40, -2147483648;
	cvta.to.local.u64 	%rd48, %rd42;
	st.local.u32 	[%rd48+24], %r215;
	mov.u32 	%r168, 6;
	sub.s32 	%r169, %r168, %r167;
	mul.wide.s32 	%rd49, %r169, 4;
	add.s64 	%rd17, %rd48, %rd49;
	ld.local.u32 	%r216, [%rd17];
	ld.local.u32 	%r217, [%rd17+-4];
	and.b32  	%r50, %r41, 31;
	setp.eq.s32	%p20, %r50, 0;
	@%p20 bra 	BB0_34;

	mov.u32 	%r170, 32;
	sub.s32 	%r171, %r170, %r50;
	shr.u32 	%r172, %r217, %r171;
	shl.b32 	%r173, %r216, %r50;
	add.s32 	%r216, %r172, %r173;
	ld.local.u32 	%r174, [%rd17+-8];
	shr.u32 	%r175, %r174, %r171;
	shl.b32 	%r176, %r217, %r50;
	add.s32 	%r217, %r175, %r176;

BB0_34:
	shr.u32 	%r177, %r217, 30;
	shl.b32 	%r178, %r216, 2;
	add.s32 	%r218, %r177, %r178;
	shl.b32 	%r56, %r217, 2;
	shr.u32 	%r179, %r218, 31;
	shr.u32 	%r180, %r216, 30;
	add.s32 	%r57, %r179, %r180;
	setp.eq.s32	%p21, %r179, 0;
	@%p21 bra 	BB0_35;

	not.b32 	%r181, %r218;
	neg.s32 	%r220, %r56;
	setp.eq.s32	%p22, %r56, 0;
	selp.u32	%r182, 1, 0, %p22;
	add.s32 	%r218, %r182, %r181;
	xor.b32  	%r219, %r47, -2147483648;
	bra.uni 	BB0_37;

BB0_35:
	mov.u32 	%r219, %r47;
	mov.u32 	%r220, %r56;

BB0_37:
	clz.b32 	%r222, %r218;
	setp.eq.s32	%p23, %r222, 0;
	shl.b32 	%r183, %r218, %r222;
	mov.u32 	%r184, 32;
	sub.s32 	%r185, %r184, %r222;
	shr.u32 	%r186, %r220, %r185;
	add.s32 	%r187, %r186, %r183;
	selp.b32	%r65, %r218, %r187, %p23;
	mov.u32 	%r188, -921707870;
	mul.hi.u32 	%r221, %r65, %r188;
	setp.eq.s32	%p24, %r47, 0;
	neg.s32 	%r189, %r57;
	selp.b32	%r223, %r57, %r189, %p24;
	setp.lt.s32	%p25, %r221, 1;
	@%p25 bra 	BB0_39;

	mul.lo.s32 	%r190, %r65, -921707870;
	shr.u32 	%r191, %r190, 31;
	shl.b32 	%r192, %r221, 1;
	add.s32 	%r221, %r191, %r192;
	add.s32 	%r222, %r222, 1;

BB0_39:
	mov.u32 	%r193, 126;
	sub.s32 	%r194, %r193, %r222;
	shl.b32 	%r195, %r194, 23;
	add.s32 	%r196, %r221, 1;
	shr.u32 	%r197, %r196, 7;
	add.s32 	%r198, %r197, 1;
	shr.u32 	%r199, %r198, 1;
	add.s32 	%r200, %r199, %r195;
	or.b32  	%r201, %r200, %r219;
	mov.b32 	 %f164, %r201;

BB0_40:
	mul.rn.f32 	%f29, %f164, %f164;
	and.b32  	%r73, %r223, 1;
	setp.eq.s32	%p26, %r73, 0;
	@%p26 bra 	BB0_42;

	mov.f32 	%f140, 0fBAB6061A;
	mov.f32 	%f141, 0f37CCF5CE;
	fma.rn.f32 	%f165, %f141, %f29, %f140;
	bra.uni 	BB0_43;

BB0_42:
	mov.f32 	%f142, 0f3C08839E;
	mov.f32 	%f143, 0fB94CA1F9;
	fma.rn.f32 	%f165, %f143, %f29, %f142;

BB0_43:
	@%p26 bra 	BB0_45;

	mov.f32 	%f144, 0f3D2AAAA5;
	fma.rn.f32 	%f145, %f165, %f29, %f144;
	mov.f32 	%f146, 0fBF000000;
	fma.rn.f32 	%f166, %f145, %f29, %f146;
	bra.uni 	BB0_46;

BB0_45:
	mov.f32 	%f147, 0fBE2AAAA3;
	fma.rn.f32 	%f148, %f165, %f29, %f147;
	mov.f32 	%f149, 0f00000000;
	fma.rn.f32 	%f166, %f148, %f29, %f149;

BB0_46:
	fma.rn.f32 	%f167, %f166, %f164, %f164;
	@%p26 bra 	BB0_48;

	mov.f32 	%f150, 0f3F800000;
	fma.rn.f32 	%f167, %f166, %f29, %f150;

BB0_48:
	and.b32  	%r202, %r223, 2;
	setp.eq.s32	%p29, %r202, 0;
	@%p29 bra 	BB0_50;

	mov.f32 	%f151, 0f00000000;
	mov.f32 	%f152, 0fBF800000;
	fma.rn.f32 	%f167, %f167, %f152, %f151;

BB0_50:
	cvt.rn.f32.f64	%f153, %fd1;
	mul.f32 	%f154, %f153, %f167;
	mul.f32 	%f155, %f153, %f161;
	st.v2.f32 	[%rd34], {%f155, %f154};

BB0_51:
	ret;
}

	// .globl	_Z9exceptionv
.visible .entry _Z9exceptionv(

)
{
	.local .align 16 .b8 	__local_depot1[400];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<43>;
	.reg .f32 	%f<9>;
	.reg .b32 	%r<125>;
	.reg .f64 	%fd<9>;
	.reg .b64 	%rd<121>;


	mov.u64 	%SPL, __local_depot1;
	cvta.local.u64 	%SP, %SPL;
	// inline asm
	call (%r75), _rt_get_exception_code, ();
	// inline asm
	setp.eq.s32	%p1, %r75, 1020;
	@%p1 bra 	BB1_61;
	bra.uni 	BB1_1;

BB1_61:
	ld.volatile.global.u32 	%r72, [_ZN21rti_internal_register14reg_rayIndex_xE];
	ld.volatile.global.u32 	%r73, [_ZN21rti_internal_register14reg_rayIndex_yE];
	ld.volatile.global.u32 	%r74, [_ZN21rti_internal_register14reg_rayIndex_zE];
	// inline asm
	call (%r115), _rt_print_active, ();
	// inline asm
	setp.eq.s32	%p42, %r115, 0;
	@%p42 bra 	BB1_63;

	add.u64 	%rd108, %SP, 384;
	add.u64 	%rd109, %SPL, 384;
	st.local.v2.u32 	[%rd109], {%r72, %r73};
	st.local.u32 	[%rd109+8], %r74;
	mov.u64 	%rd110, $str;
	cvta.global.u64 	%rd111, %rd110;
	// Callseq Start 18
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd111;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd108;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r116, [retval0+0];
	
	//{
	}// Callseq End 18
	bra.uni 	BB1_63;

BB1_1:
	setp.eq.s32	%p2, %r75, 1005;
	@%p2 bra 	BB1_59;
	bra.uni 	BB1_2;

BB1_59:
	ld.volatile.global.u32 	%r69, [_ZN21rti_internal_register14reg_rayIndex_xE];
	ld.volatile.global.u32 	%r70, [_ZN21rti_internal_register14reg_rayIndex_yE];
	ld.volatile.global.u32 	%r71, [_ZN21rti_internal_register14reg_rayIndex_zE];
	// inline asm
	call (%r113), _rt_print_active, ();
	// inline asm
	setp.eq.s32	%p41, %r113, 0;
	@%p41 bra 	BB1_63;

	add.u64 	%rd104, %SP, 384;
	add.u64 	%rd105, %SPL, 384;
	st.local.v2.u32 	[%rd105], {%r69, %r70};
	st.local.u32 	[%rd105+8], %r71;
	mov.u64 	%rd106, $str1;
	cvta.global.u64 	%rd107, %rd106;
	// Callseq Start 17
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd107;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd104;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r114, [retval0+0];
	
	//{
	}// Callseq End 17
	bra.uni 	BB1_63;

BB1_2:
	setp.eq.s32	%p3, %r75, 1021;
	@%p3 bra 	BB1_53;
	bra.uni 	BB1_3;

BB1_53:
	ld.volatile.global.u32 	%r63, [_ZN21rti_internal_register21reg_exception_detail0E];
	ld.volatile.global.u32 	%r64, [_ZN21rti_internal_register14reg_rayIndex_xE];
	ld.volatile.global.u32 	%r65, [_ZN21rti_internal_register14reg_rayIndex_yE];
	ld.volatile.global.u32 	%r66, [_ZN21rti_internal_register14reg_rayIndex_zE];
	ld.volatile.global.u64 	%rd18, [_ZN21rti_internal_register24reg_exception_64_detail0E];
	ld.volatile.global.u32 	%r67, [_ZN21rti_internal_register21reg_exception_detail2E];
	ld.volatile.global.u64 	%rd19, [_ZN21rti_internal_register24reg_exception_64_detail1E];
	mov.u64 	%rd120, 1;
	setp.lt.u32	%p38, %r63, 2;
	mov.u64 	%rd119, %rd120;
	@%p38 bra 	BB1_55;

	ld.volatile.global.u64 	%rd119, [_ZN21rti_internal_register24reg_exception_64_detail2E];

BB1_55:
	setp.lt.u32	%p39, %r63, 3;
	@%p39 bra 	BB1_57;

	ld.volatile.global.u64 	%rd120, [_ZN21rti_internal_register24reg_exception_64_detail3E];

BB1_57:
	ld.volatile.global.u32 	%r68, [_ZN21rti_internal_register21reg_exception_detail1E];
	ld.volatile.global.u64 	%rd24, [_ZN21rti_internal_register24reg_exception_64_detail4E];
	ld.volatile.global.u64 	%rd25, [_ZN21rti_internal_register24reg_exception_64_detail5E];
	ld.volatile.global.u64 	%rd26, [_ZN21rti_internal_register24reg_exception_64_detail6E];
	// inline asm
	call (%r111), _rt_print_active, ();
	// inline asm
	setp.eq.s32	%p40, %r111, 0;
	@%p40 bra 	BB1_63;

	add.u64 	%rd100, %SP, 296;
	add.u64 	%rd101, %SPL, 296;
	st.local.v2.u32 	[%rd101], {%r64, %r65};
	st.local.u32 	[%rd101+24], %r67;
	st.local.u32 	[%rd101+56], %r68;
	st.local.v2.u32 	[%rd101+8], {%r66, %r63};
	st.local.u64 	[%rd101+16], %rd18;
	st.local.u64 	[%rd101+32], %rd19;
	st.local.u64 	[%rd101+40], %rd119;
	st.local.u64 	[%rd101+48], %rd120;
	st.local.u64 	[%rd101+64], %rd24;
	st.local.u64 	[%rd101+72], %rd25;
	st.local.u64 	[%rd101+80], %rd26;
	mov.u64 	%rd102, $str2;
	cvta.global.u64 	%rd103, %rd102;
	// Callseq Start 16
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd103;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd100;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r112, [retval0+0];
	
	//{
	}// Callseq End 16

BB1_63:
	ld.global.v2.u32 	{%r119, %r120}, [launch_index];
	cvt.u64.u32	%rd114, %r119;
	cvt.u64.u32	%rd115, %r120;
	mov.u64 	%rd118, output_buffer;
	cvta.global.u64 	%rd113, %rd118;
	mov.u32 	%r117, 2;
	mov.u32 	%r118, 4;
	mov.u64 	%rd117, 0;
	// inline asm
	call (%rd112), _rt_buffer_get_64, (%rd113, %r117, %r118, %rd114, %rd115, %rd117, %rd117);
	// inline asm
	mov.u32 	%r123, 0;
	st.u32 	[%rd112], %r123;
	ret;

BB1_3:
	setp.eq.s32	%p4, %r75, 1006;
	add.u64 	%rd27, %SP, 272;
	add.u64 	%rd28, %SPL, 272;
	add.s64 	%rd1, %rd28, 4;
	@%p4 bra 	BB1_44;
	bra.uni 	BB1_4;

BB1_44:
	ld.volatile.global.u32 	%r104, [_ZN21rti_internal_register21reg_exception_detail1E];
	setp.eq.s32	%p32, %r104, 1;
	@%p32 bra 	BB1_51;

	setp.eq.s32	%p33, %r104, 2;
	@%p33 bra 	BB1_49;
	bra.uni 	BB1_46;

BB1_49:
	ld.volatile.global.u32 	%r56, [_ZN21rti_internal_register21reg_exception_detail0E];
	ld.volatile.global.u32 	%r57, [_ZN21rti_internal_register14reg_rayIndex_xE];
	ld.volatile.global.u32 	%r58, [_ZN21rti_internal_register14reg_rayIndex_yE];
	ld.volatile.global.u32 	%r59, [_ZN21rti_internal_register14reg_rayIndex_zE];
	ld.volatile.global.u64 	%rd16, [_ZN21rti_internal_register24reg_exception_64_detail0E];
	// inline asm
	call (%r107), _rt_print_active, ();
	// inline asm
	setp.eq.s32	%p36, %r107, 0;
	@%p36 bra 	BB1_63;

	st.local.u32 	[%rd28], %r56;
	st.local.u32 	[%rd1], %r57;
	st.local.v2.u32 	[%rd1+4], {%r58, %r59};
	st.local.u64 	[%rd1+12], %rd16;
	mov.u64 	%rd92, $str4;
	cvta.global.u64 	%rd93, %rd92;
	// Callseq Start 14
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd93;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd27;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r108, [retval0+0];
	
	//{
	}// Callseq End 14
	bra.uni 	BB1_63;

BB1_4:
	setp.eq.s32	%p5, %r75, 1007;
	add.u64 	%rd29, %SP, 256;
	add.u64 	%rd30, %SPL, 256;
	add.s64 	%rd2, %rd30, 4;
	@%p5 bra 	BB1_35;
	bra.uni 	BB1_5;

BB1_35:
	ld.volatile.global.u32 	%r97, [_ZN21rti_internal_register21reg_exception_detail1E];
	setp.eq.s32	%p26, %r97, 1;
	@%p26 bra 	BB1_42;

	setp.eq.s32	%p27, %r97, 2;
	@%p27 bra 	BB1_40;
	bra.uni 	BB1_37;

BB1_40:
	ld.volatile.global.u32 	%r45, [_ZN21rti_internal_register21reg_exception_detail0E];
	ld.volatile.global.u32 	%r46, [_ZN21rti_internal_register14reg_rayIndex_xE];
	ld.volatile.global.u32 	%r47, [_ZN21rti_internal_register14reg_rayIndex_yE];
	ld.volatile.global.u32 	%r48, [_ZN21rti_internal_register14reg_rayIndex_zE];
	// inline asm
	call (%r100), _rt_print_active, ();
	// inline asm
	setp.eq.s32	%p30, %r100, 0;
	@%p30 bra 	BB1_63;

	st.local.u32 	[%rd30], %r45;
	st.local.u32 	[%rd2], %r46;
	st.local.v2.u32 	[%rd2+4], {%r47, %r48};
	mov.u64 	%rd80, $str7;
	cvta.global.u64 	%rd81, %rd80;
	// Callseq Start 11
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd81;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd29;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r101, [retval0+0];
	
	//{
	}// Callseq End 11
	bra.uni 	BB1_63;

BB1_5:
	setp.eq.s32	%p6, %r75, 1018;
	@%p6 bra 	BB1_26;
	bra.uni 	BB1_6;

BB1_26:
	ld.volatile.global.u32 	%r90, [_ZN21rti_internal_register21reg_exception_detail1E];
	setp.eq.s32	%p20, %r90, 1;
	@%p20 bra 	BB1_33;

	setp.eq.s32	%p21, %r90, 2;
	@%p21 bra 	BB1_31;
	bra.uni 	BB1_28;

BB1_31:
	ld.volatile.global.u32 	%r35, [_ZN21rti_internal_register21reg_exception_detail0E];
	ld.volatile.global.u32 	%r36, [_ZN21rti_internal_register14reg_rayIndex_xE];
	ld.volatile.global.u32 	%r37, [_ZN21rti_internal_register14reg_rayIndex_yE];
	ld.volatile.global.u32 	%r38, [_ZN21rti_internal_register14reg_rayIndex_zE];
	ld.volatile.global.u64 	%rd13, [_ZN21rti_internal_register24reg_exception_64_detail0E];
	// inline asm
	call (%r93), _rt_print_active, ();
	// inline asm
	setp.eq.s32	%p24, %r93, 0;
	@%p24 bra 	BB1_63;

	mov.u64 	%rd64, $str11;
	cvta.global.u64 	%rd65, %rd64;
	add.u64 	%rd66, %SP, 224;
	add.u64 	%rd67, %SPL, 224;
	st.local.u64 	[%rd67], %rd65;
	st.local.u64 	[%rd67+24], %rd13;
	st.local.v2.u32 	[%rd67+8], {%r35, %r36};
	st.local.v2.u32 	[%rd67+16], {%r37, %r38};
	mov.u64 	%rd68, $str10;
	cvta.global.u64 	%rd69, %rd68;
	// Callseq Start 8
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd69;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd66;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r94, [retval0+0];
	
	//{
	}// Callseq End 8
	bra.uni 	BB1_63;

BB1_51:
	ld.volatile.global.u32 	%r60, [_ZN21rti_internal_register14reg_rayIndex_xE];
	ld.volatile.global.u32 	%r61, [_ZN21rti_internal_register14reg_rayIndex_yE];
	ld.volatile.global.u32 	%r62, [_ZN21rti_internal_register14reg_rayIndex_zE];
	ld.volatile.global.u64 	%rd17, [_ZN21rti_internal_register24reg_exception_64_detail0E];
	// inline asm
	call (%r109), _rt_print_active, ();
	// inline asm
	setp.eq.s32	%p37, %r109, 0;
	@%p37 bra 	BB1_63;

	st.local.u32 	[%rd28], %r60;
	st.local.u32 	[%rd1], %r61;
	st.local.u32 	[%rd1+4], %r62;
	st.local.u64 	[%rd1+12], %rd17;
	mov.u64 	%rd96, $str3;
	cvta.global.u64 	%rd97, %rd96;
	// Callseq Start 15
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd97;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd27;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r110, [retval0+0];
	
	//{
	}// Callseq End 15
	bra.uni 	BB1_63;

BB1_46:
	setp.ne.s32	%p34, %r104, 3;
	@%p34 bra 	BB1_63;

	ld.volatile.global.u32 	%r52, [_ZN21rti_internal_register21reg_exception_detail0E];
	ld.volatile.global.u32 	%r53, [_ZN21rti_internal_register14reg_rayIndex_xE];
	ld.volatile.global.u32 	%r54, [_ZN21rti_internal_register14reg_rayIndex_yE];
	ld.volatile.global.u32 	%r55, [_ZN21rti_internal_register14reg_rayIndex_zE];
	ld.volatile.global.u64 	%rd15, [_ZN21rti_internal_register24reg_exception_64_detail0E];
	// inline asm
	call (%r105), _rt_print_active, ();
	// inline asm
	setp.eq.s32	%p35, %r105, 0;
	@%p35 bra 	BB1_63;

	st.local.u32 	[%rd28], %r52;
	st.local.u32 	[%rd1], %r53;
	st.local.v2.u32 	[%rd1+4], {%r54, %r55};
	st.local.u64 	[%rd1+12], %rd15;
	mov.u64 	%rd88, $str5;
	cvta.global.u64 	%rd89, %rd88;
	// Callseq Start 13
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd89;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd27;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r106, [retval0+0];
	
	//{
	}// Callseq End 13
	bra.uni 	BB1_63;

BB1_6:
	setp.eq.s32	%p7, %r75, 1019;
	@%p7 bra 	BB1_24;
	bra.uni 	BB1_7;

BB1_24:
	ld.volatile.global.u32 	%r28, [_ZN21rti_internal_register14reg_rayIndex_xE];
	ld.volatile.global.u32 	%r29, [_ZN21rti_internal_register14reg_rayIndex_yE];
	ld.volatile.global.u32 	%r30, [_ZN21rti_internal_register14reg_rayIndex_zE];
	ld.volatile.global.u64 	%rd9, [_ZN21rti_internal_register24reg_exception_64_detail0E];
	ld.volatile.global.u64 	%rd10, [_ZN21rti_internal_register24reg_exception_64_detail1E];
	ld.volatile.global.u64 	%rd11, [_ZN21rti_internal_register24reg_exception_64_detail2E];
	// inline asm
	call (%r88), _rt_print_active, ();
	// inline asm
	setp.eq.s32	%p19, %r88, 0;
	@%p19 bra 	BB1_63;

	add.u64 	%rd56, %SP, 176;
	add.u64 	%rd57, %SPL, 176;
	st.local.v2.u32 	[%rd57], {%r28, %r29};
	st.local.u32 	[%rd57+8], %r30;
	st.local.u64 	[%rd57+16], %rd9;
	st.local.u64 	[%rd57+24], %rd10;
	st.local.u64 	[%rd57+32], %rd11;
	mov.u64 	%rd58, $str13;
	cvta.global.u64 	%rd59, %rd58;
	// Callseq Start 6
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd59;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd56;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r89, [retval0+0];
	
	//{
	}// Callseq End 6
	bra.uni 	BB1_63;

BB1_42:
	ld.volatile.global.u32 	%r49, [_ZN21rti_internal_register14reg_rayIndex_xE];
	ld.volatile.global.u32 	%r50, [_ZN21rti_internal_register14reg_rayIndex_yE];
	ld.volatile.global.u32 	%r51, [_ZN21rti_internal_register14reg_rayIndex_zE];
	// inline asm
	call (%r102), _rt_print_active, ();
	// inline asm
	setp.eq.s32	%p31, %r102, 0;
	@%p31 bra 	BB1_63;

	add.u64 	%rd82, %SP, 384;
	add.u64 	%rd83, %SPL, 384;
	st.local.v2.u32 	[%rd83], {%r49, %r50};
	st.local.u32 	[%rd83+8], %r51;
	mov.u64 	%rd84, $str6;
	cvta.global.u64 	%rd85, %rd84;
	// Callseq Start 12
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd85;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd82;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r103, [retval0+0];
	
	//{
	}// Callseq End 12
	bra.uni 	BB1_63;

BB1_37:
	setp.ne.s32	%p28, %r97, 3;
	@%p28 bra 	BB1_63;

	ld.volatile.global.u32 	%r42, [_ZN21rti_internal_register14reg_rayIndex_xE];
	ld.volatile.global.u32 	%r43, [_ZN21rti_internal_register14reg_rayIndex_yE];
	ld.volatile.global.u32 	%r44, [_ZN21rti_internal_register14reg_rayIndex_zE];
	// inline asm
	call (%r98), _rt_print_active, ();
	// inline asm
	setp.eq.s32	%p29, %r98, 0;
	@%p29 bra 	BB1_63;

	add.u64 	%rd74, %SP, 384;
	add.u64 	%rd75, %SPL, 384;
	st.local.v2.u32 	[%rd75], {%r42, %r43};
	st.local.u32 	[%rd75+8], %r44;
	mov.u64 	%rd76, $str8;
	cvta.global.u64 	%rd77, %rd76;
	// Callseq Start 10
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd77;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd74;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r99, [retval0+0];
	
	//{
	}// Callseq End 10
	bra.uni 	BB1_63;

BB1_7:
	setp.eq.s32	%p8, %r75, 1022;
	@%p8 bra 	BB1_22;
	bra.uni 	BB1_8;

BB1_22:
	ld.volatile.global.u32 	%r16, [_ZN21rti_internal_register14reg_rayIndex_xE];
	ld.volatile.global.u32 	%r17, [_ZN21rti_internal_register14reg_rayIndex_yE];
	ld.volatile.global.u32 	%r18, [_ZN21rti_internal_register14reg_rayIndex_zE];
	ld.volatile.global.u64 	%rd8, [_ZN21rti_internal_register24reg_exception_64_detail0E];
	ld.volatile.global.u32 	%r19, [_ZN21rti_internal_register21reg_exception_detail0E];
	ld.volatile.global.u32 	%r20, [_ZN21rti_internal_register21reg_exception_detail1E];
	ld.volatile.global.u32 	%r21, [_ZN21rti_internal_register21reg_exception_detail2E];
	ld.volatile.global.u32 	%r22, [_ZN21rti_internal_register21reg_exception_detail3E];
	ld.volatile.global.u32 	%r23, [_ZN21rti_internal_register21reg_exception_detail4E];
	ld.volatile.global.u32 	%r24, [_ZN21rti_internal_register21reg_exception_detail5E];
	ld.volatile.global.u32 	%r25, [_ZN21rti_internal_register21reg_exception_detail6E];
	ld.volatile.global.u32 	%r26, [_ZN21rti_internal_register21reg_exception_detail7E];
	ld.volatile.global.u32 	%r27, [_ZN21rti_internal_register21reg_exception_detail8E];
	// inline asm
	call (%r86), _rt_print_active, ();
	// inline asm
	setp.eq.s32	%p18, %r86, 0;
	@%p18 bra 	BB1_63;

	mov.b32 	 %f1, %r19;
	cvt.f64.f32	%fd1, %f1;
	mov.b32 	 %f2, %r20;
	mov.b32 	 %f3, %r21;
	mov.b32 	 %f4, %r22;
	mov.b32 	 %f5, %r23;
	mov.b32 	 %f6, %r24;
	cvt.f64.f32	%fd2, %f6;
	mov.b32 	 %f7, %r26;
	mov.b32 	 %f8, %r27;
	add.u64 	%rd51, %SP, 80;
	add.u64 	%rd52, %SPL, 80;
	st.local.v2.u32 	[%rd52], {%r16, %r17};
	st.local.u32 	[%rd52+8], %r18;
	mov.b64 	 %rd53, %fd1;
	st.local.u32 	[%rd52+72], %r25;
	st.local.v2.u64 	[%rd52+16], {%rd8, %rd53};
	cvt.f64.f32	%fd3, %f3;
	cvt.f64.f32	%fd4, %f2;
	st.local.v2.f64 	[%rd52+32], {%fd4, %fd3};
	cvt.f64.f32	%fd5, %f5;
	cvt.f64.f32	%fd6, %f4;
	st.local.v2.f64 	[%rd52+48], {%fd6, %fd5};
	st.local.f64 	[%rd52+64], %fd2;
	cvt.f64.f32	%fd7, %f8;
	cvt.f64.f32	%fd8, %f7;
	st.local.v2.f64 	[%rd52+80], {%fd8, %fd7};
	mov.u64 	%rd54, $str14;
	cvta.global.u64 	%rd55, %rd54;
	// Callseq Start 5
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd55;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd51;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r87, [retval0+0];
	
	//{
	}// Callseq End 5
	bra.uni 	BB1_63;

BB1_33:
	ld.volatile.global.u32 	%r39, [_ZN21rti_internal_register14reg_rayIndex_xE];
	ld.volatile.global.u32 	%r40, [_ZN21rti_internal_register14reg_rayIndex_yE];
	ld.volatile.global.u32 	%r41, [_ZN21rti_internal_register14reg_rayIndex_zE];
	ld.volatile.global.u64 	%rd14, [_ZN21rti_internal_register24reg_exception_64_detail0E];
	// inline asm
	call (%r95), _rt_print_active, ();
	// inline asm
	setp.eq.s32	%p25, %r95, 0;
	@%p25 bra 	BB1_63;

	st.local.u32 	[%rd28], %r39;
	st.local.u32 	[%rd1], %r40;
	st.local.u32 	[%rd1+4], %r41;
	st.local.u64 	[%rd1+12], %rd14;
	mov.u64 	%rd72, $str9;
	cvta.global.u64 	%rd73, %rd72;
	// Callseq Start 9
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd73;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd27;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r96, [retval0+0];
	
	//{
	}// Callseq End 9
	bra.uni 	BB1_63;

BB1_28:
	setp.ne.s32	%p22, %r90, 3;
	@%p22 bra 	BB1_63;

	ld.volatile.global.u32 	%r31, [_ZN21rti_internal_register21reg_exception_detail0E];
	ld.volatile.global.u32 	%r32, [_ZN21rti_internal_register14reg_rayIndex_xE];
	ld.volatile.global.u32 	%r33, [_ZN21rti_internal_register14reg_rayIndex_yE];
	ld.volatile.global.u32 	%r34, [_ZN21rti_internal_register14reg_rayIndex_zE];
	ld.volatile.global.u64 	%rd12, [_ZN21rti_internal_register24reg_exception_64_detail0E];
	// inline asm
	call (%r91), _rt_print_active, ();
	// inline asm
	setp.eq.s32	%p23, %r91, 0;
	@%p23 bra 	BB1_63;

	st.local.u32 	[%rd28], %r31;
	st.local.u32 	[%rd1], %r32;
	st.local.v2.u32 	[%rd1+4], {%r33, %r34};
	st.local.u64 	[%rd1+12], %rd12;
	mov.u64 	%rd62, $str12;
	cvta.global.u64 	%rd63, %rd62;
	// Callseq Start 7
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd63;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd27;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r92, [retval0+0];
	
	//{
	}// Callseq End 7
	bra.uni 	BB1_63;

BB1_8:
	setp.eq.s32	%p9, %r75, 1003;
	@%p9 bra 	BB1_20;
	bra.uni 	BB1_9;

BB1_20:
	ld.volatile.global.u32 	%r13, [_ZN21rti_internal_register14reg_rayIndex_xE];
	ld.volatile.global.u32 	%r14, [_ZN21rti_internal_register14reg_rayIndex_yE];
	ld.volatile.global.u32 	%r15, [_ZN21rti_internal_register14reg_rayIndex_zE];
	ld.volatile.global.u64 	%rd4, [_ZN21rti_internal_register24reg_exception_64_detail0E];
	ld.volatile.global.u64 	%rd5, [_ZN21rti_internal_register24reg_exception_64_detail1E];
	ld.volatile.global.u64 	%rd6, [_ZN21rti_internal_register24reg_exception_64_detail2E];
	ld.volatile.global.u64 	%rd7, [_ZN21rti_internal_register24reg_exception_64_detail3E];
	// inline asm
	call (%r84), _rt_print_active, ();
	// inline asm
	setp.eq.s32	%p17, %r84, 0;
	@%p17 bra 	BB1_63;

	add.u64 	%rd47, %SP, 32;
	add.u64 	%rd48, %SPL, 32;
	st.local.v2.u32 	[%rd48], {%r13, %r14};
	st.local.u32 	[%rd48+8], %r15;
	st.local.v2.u64 	[%rd48+16], {%rd4, %rd5};
	st.local.v2.u64 	[%rd48+32], {%rd6, %rd7};
	mov.u64 	%rd49, $str15;
	cvta.global.u64 	%rd50, %rd49;
	// Callseq Start 4
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd50;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd47;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r85, [retval0+0];
	
	//{
	}// Callseq End 4
	bra.uni 	BB1_63;

BB1_9:
	setp.eq.s32	%p10, %r75, 1004;
	@%p10 bra 	BB1_18;
	bra.uni 	BB1_10;

BB1_18:
	ld.volatile.global.u32 	%r9, [_ZN21rti_internal_register14reg_rayIndex_xE];
	ld.volatile.global.u32 	%r10, [_ZN21rti_internal_register14reg_rayIndex_yE];
	ld.volatile.global.u32 	%r11, [_ZN21rti_internal_register14reg_rayIndex_zE];
	ld.volatile.global.u64 	%rd3, [_ZN21rti_internal_register24reg_exception_64_detail0E];
	ld.volatile.global.u32 	%r12, [_ZN21rti_internal_register21reg_exception_detail0E];
	// inline asm
	call (%r82), _rt_print_active, ();
	// inline asm
	setp.eq.s32	%p16, %r82, 0;
	@%p16 bra 	BB1_63;

	add.u64 	%rd43, %SP, 0;
	add.u64 	%rd44, %SPL, 0;
	st.local.v2.u32 	[%rd44], {%r9, %r10};
	st.local.u32 	[%rd44+8], %r11;
	st.local.u32 	[%rd44+24], %r12;
	st.local.u64 	[%rd44+16], %rd3;
	mov.u64 	%rd45, $str16;
	cvta.global.u64 	%rd46, %rd45;
	// Callseq Start 3
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd46;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd43;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r83, [retval0+0];
	
	//{
	}// Callseq End 3
	bra.uni 	BB1_63;

BB1_10:
	add.s32 	%r2, %r75, -1024;
	setp.lt.u32	%p11, %r2, 64512;
	@%p11 bra 	BB1_16;
	bra.uni 	BB1_11;

BB1_16:
	ld.volatile.global.u32 	%r6, [_ZN21rti_internal_register14reg_rayIndex_xE];
	ld.volatile.global.u32 	%r7, [_ZN21rti_internal_register14reg_rayIndex_yE];
	ld.volatile.global.u32 	%r8, [_ZN21rti_internal_register14reg_rayIndex_zE];
	// inline asm
	call (%r80), _rt_print_active, ();
	// inline asm
	setp.eq.s32	%p15, %r80, 0;
	@%p15 bra 	BB1_63;

	add.s32 	%r124, %r75, -1024;
	st.local.u32 	[%rd30], %r124;
	st.local.u32 	[%rd2], %r6;
	st.local.v2.u32 	[%rd2+4], {%r7, %r8};
	mov.u64 	%rd41, $str17;
	cvta.global.u64 	%rd42, %rd41;
	// Callseq Start 2
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd42;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd29;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r81, [retval0+0];
	
	//{
	}// Callseq End 2
	bra.uni 	BB1_63;

BB1_11:
	setp.eq.s32	%p12, %r75, 1023;
	ld.volatile.global.u32 	%r3, [_ZN21rti_internal_register14reg_rayIndex_xE];
	ld.volatile.global.u32 	%r4, [_ZN21rti_internal_register14reg_rayIndex_yE];
	ld.volatile.global.u32 	%r5, [_ZN21rti_internal_register14reg_rayIndex_zE];
	@%p12 bra 	BB1_14;
	bra.uni 	BB1_12;

BB1_14:
	// inline asm
	call (%r78), _rt_print_active, ();
	// inline asm
	setp.eq.s32	%p14, %r78, 0;
	@%p14 bra 	BB1_63;

	add.u64 	%rd35, %SP, 384;
	add.u64 	%rd36, %SPL, 384;
	st.local.v2.u32 	[%rd36], {%r3, %r4};
	st.local.u32 	[%rd36+8], %r5;
	mov.u64 	%rd37, $str18;
	cvta.global.u64 	%rd38, %rd37;
	// Callseq Start 1
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd38;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd35;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r79, [retval0+0];
	
	//{
	}// Callseq End 1
	bra.uni 	BB1_63;

BB1_12:
	// inline asm
	call (%r76), _rt_print_active, ();
	// inline asm
	setp.eq.s32	%p13, %r76, 0;
	@%p13 bra 	BB1_63;

	add.u64 	%rd31, %SP, 384;
	add.u64 	%rd32, %SPL, 384;
	st.local.v2.u32 	[%rd32], {%r3, %r4};
	st.local.u32 	[%rd32+8], %r5;
	mov.u64 	%rd33, $str19;
	cvta.global.u64 	%rd34, %rd33;
	// Callseq Start 0
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd34;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd31;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r77, [retval0+0];
	
	//{
	}// Callseq End 0
	bra.uni 	BB1_63;
}

	// .globl	_Z11closest_hitv
.visible .entry _Z11closest_hitv(

)
{
	.reg .pred 	%p<4>;
	.reg .f32 	%f<106>;
	.reg .b32 	%r<14>;
	.reg .b64 	%rd<25>;


	ld.global.f32 	%f33, [shading_normal];
	ld.global.f32 	%f34, [shading_normal+4];
	ld.global.f32 	%f35, [shading_normal+8];
	mov.u32 	%r3, 7937;
	mov.f32 	%f36, 0f00000000;
	// inline asm
	call (%f29, %f30, %f31, %f32), _rt_transform_tuple, (%r3, %f33, %f34, %f35, %f36);
	// inline asm
	mul.f32 	%f37, %f30, %f30;
	fma.rn.f32 	%f38, %f29, %f29, %f37;
	fma.rn.f32 	%f39, %f31, %f31, %f38;
	sqrt.rn.f32 	%f40, %f39;
	rcp.rn.f32 	%f41, %f40;
	mul.f32 	%f42, %f29, %f41;
	mul.f32 	%f43, %f30, %f41;
	mul.f32 	%f44, %f31, %f41;
	ld.global.f32 	%f45, [ray+12];
	mul.f32 	%f46, %f45, %f42;
	ld.global.f32 	%f47, [ray+16];
	mul.f32 	%f48, %f43, %f47;
	neg.f32 	%f49, %f48;
	sub.f32 	%f50, %f49, %f46;
	ld.global.f32 	%f51, [ray+20];
	mul.f32 	%f52, %f44, %f51;
	sub.f32 	%f53, %f50, %f52;
	mov.b32 	 %r6, %f53;
	and.b32  	%r7, %r6, -2147483648;
	or.b32  	%r8, %r7, 1065353216;
	mov.b32 	 %f54, %r8;
	mul.f32 	%f1, %f42, %f54;
	mul.f32 	%f2, %f43, %f54;
	mul.f32 	%f3, %f44, %f54;
	ld.global.f32 	%f55, [ambient_light_color];
	ld.global.f32 	%f56, [Ka];
	mul.f32 	%f99, %f56, %f55;
	ld.global.f32 	%f57, [ambient_light_color+4];
	ld.global.f32 	%f58, [Ka+4];
	mul.f32 	%f98, %f58, %f57;
	ld.global.f32 	%f59, [ambient_light_color+8];
	ld.global.f32 	%f60, [Ka+8];
	mul.f32 	%f97, %f60, %f59;
	ld.global.f32 	%f61, [t_hit];
	ld.global.f32 	%f62, [ray];
	fma.rn.f32 	%f7, %f61, %f45, %f62;
	ld.global.f32 	%f63, [ray+4];
	fma.rn.f32 	%f8, %f61, %f47, %f63;
	ld.global.f32 	%f64, [ray+8];
	fma.rn.f32 	%f9, %f61, %f51, %f64;
	mov.u64 	%rd9, lights;
	cvta.global.u64 	%rd7, %rd9;
	mov.u32 	%r4, 1;
	mov.u32 	%r5, 32;
	// inline asm
	call (%rd3, %rd4, %rd5, %rd6), _rt_buffer_get_size_64, (%rd7, %r4, %r5);
	// inline asm
	cvt.u32.u64	%r9, %rd3;
	setp.eq.s32	%p1, %r9, 0;
	mov.u64 	%rd8, 0;
	@%p1 bra 	BB2_5;

	mov.u64 	%rd24, %rd8;

BB2_2:
	// inline asm
	call (%rd10), _rt_buffer_get_64, (%rd7, %r4, %r5, %rd24, %rd8, %rd8, %rd8);
	// inline asm
	ld.f32 	%f13, [%rd10];
	ld.f32 	%f14, [%rd10+4];
	ld.f32 	%f15, [%rd10+8];
	ld.f32 	%f16, [%rd10+12];
	ld.f32 	%f17, [%rd10+16];
	ld.f32 	%f18, [%rd10+20];
	sub.f32 	%f65, %f13, %f7;
	sub.f32 	%f66, %f14, %f8;
	sub.f32 	%f67, %f15, %f9;
	mul.f32 	%f68, %f66, %f66;
	fma.rn.f32 	%f69, %f65, %f65, %f68;
	fma.rn.f32 	%f70, %f67, %f67, %f69;
	sqrt.rn.f32 	%f71, %f70;
	rcp.rn.f32 	%f72, %f71;
	mul.f32 	%f73, %f65, %f72;
	mul.f32 	%f74, %f66, %f72;
	mul.f32 	%f75, %f67, %f72;
	mul.f32 	%f76, %f2, %f74;
	fma.rn.f32 	%f77, %f1, %f73, %f76;
	fma.rn.f32 	%f19, %f3, %f75, %f77;
	setp.leu.f32	%p2, %f19, 0f00000000;
	@%p2 bra 	BB2_4;

	ld.global.f32 	%f78, [Kd];
	mul.f32 	%f79, %f19, %f78;
	ld.global.f32 	%f80, [Kd+4];
	mul.f32 	%f81, %f19, %f80;
	ld.global.f32 	%f82, [Kd+8];
	mul.f32 	%f83, %f19, %f82;
	fma.rn.f32 	%f99, %f16, %f79, %f99;
	fma.rn.f32 	%f98, %f17, %f81, %f98;
	fma.rn.f32 	%f97, %f18, %f83, %f97;

BB2_4:
	// inline asm
	call (%rd17, %rd18, %rd19, %rd20), _rt_buffer_get_size_64, (%rd7, %r4, %r5);
	// inline asm
	and.b64  	%rd23, %rd17, 4294967295;
	add.s64 	%rd24, %rd24, 1;
	setp.lt.u64	%p3, %rd24, %rd23;
	@%p3 bra 	BB2_2;

BB2_5:
	st.global.f32 	[prd_radiance], %f99;
	st.global.f32 	[prd_radiance+4], %f98;
	st.global.f32 	[prd_radiance+8], %f97;
	ld.global.f32 	%f84, [ray+12];
	ld.global.f32 	%f85, [t_hit];
	mul.f32 	%f86, %f85, %f84;
	ld.global.f32 	%f87, [ray+16];
	mul.f32 	%f88, %f85, %f87;
	ld.global.f32 	%f89, [ray+20];
	mul.f32 	%f90, %f85, %f89;
	ld.global.f32 	%f91, [l1];
	ld.global.f32 	%f92, [l1+4];
	mul.f32 	%f93, %f88, %f92;
	fma.rn.f32 	%f94, %f86, %f91, %f93;
	ld.global.f32 	%f95, [l1+8];
	fma.rn.f32 	%f96, %f90, %f95, %f94;
	st.global.f32 	[prd_radiance+12], %f96;
	ret;
}

	// .globl	_Z4missv
.visible .entry _Z4missv(

)
{
	.reg .f32 	%f<4>;
	.reg .b32 	%r<2>;


	ld.global.f32 	%f1, [bg_color];
	ld.global.f32 	%f2, [bg_color+4];
	ld.global.f32 	%f3, [bg_color+8];
	st.global.f32 	[prd_radiance], %f1;
	st.global.f32 	[prd_radiance+4], %f2;
	st.global.f32 	[prd_radiance+8], %f3;
	mov.u32 	%r1, -1082130432;
	st.global.u32 	[prd_radiance+12], %r1;
	ret;
}

	// .globl	_Z4holov
.visible .entry _Z4holov(

)
{
	.local .align 4 .b8 	__local_depot4[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<39>;
	.reg .f32 	%f<162>;
	.reg .b32 	%r<227>;
	.reg .f64 	%fd<17>;
	.reg .b64 	%rd<56>;


	mov.u64 	%SPL, __local_depot4;
	ld.global.f32 	%f55, [fencengshu];
	mov.f32 	%f158, 0f00000000;
	setp.leu.f32	%p1, %f55, 0f00000000;
	mov.f32 	%f159, %f158;
	@%p1 bra 	BB4_49;

	ld.global.v2.u32 	{%r77, %r78}, [launch_index];
	mov.u32 	%r206, 0;
	ld.global.v2.u32 	{%r81, %r82}, [launch_dim];
	shr.u32 	%r84, %r81, 1;
	sub.s32 	%r85, %r77, %r84;
	mul.lo.s32 	%r86, %r85, %r85;
	cvt.rn.f64.s32	%fd2, %r86;
	mul.f64 	%fd3, %fd2, 0d3F80624DD2F1A9FC;
	shr.u32 	%r88, %r82, 1;
	sub.s32 	%r89, %r78, %r88;
	cvt.rn.f64.s32	%fd4, %r89;
	mul.f64 	%fd5, %fd4, 0d3F80624DD2F1A9FC;
	mul.f64 	%fd6, %fd4, %fd5;
	mul.f64 	%fd7, %fd6, 0d3F80624DD2F1A9FC;
	fma.rn.f64 	%fd1, %fd3, 0d3F80624DD2F1A9FC, %fd7;
	add.u64 	%rd1, %SPL, 0;
	add.s64 	%rd2, %rd1, 24;
	cvt.u64.u32	%rd3, %r77;
	cvt.u64.u32	%rd4, %r78;
	mov.f32 	%f143, 0f00000000;
	mov.f32 	%f158, %f143;
	mov.f32 	%f159, %f143;

BB4_2:
	ld.global.f32 	%f59, [juli];
	ld.global.f32 	%f60, [z];
	fma.rn.f32 	%f61, %f143, %f59, %f60;
	cvt.f64.f32	%fd8, %f61;
	mov.f64 	%fd9, 0d40B3346B9BAEE9CE;
	div.rn.f64 	%fd10, %fd9, %fd8;
	mul.f64 	%fd11, %fd1, %fd10;
	cvt.rn.f32.f64	%f152, %fd11;
	abs.f32 	%f5, %f152;
	setp.neu.f32	%p2, %f5, 0f7F800000;
	mov.f32 	%f146, %f152;
	@%p2 bra 	BB4_4;

	mov.f32 	%f62, 0f00000000;
	mul.rn.f32 	%f146, %f152, %f62;

BB4_4:
	mul.f32 	%f63, %f146, 0f3F22F983;
	cvt.rni.s32.f32	%r216, %f63;
	cvt.rn.f32.s32	%f64, %r216;
	neg.f32 	%f65, %f64;
	mov.f32 	%f66, 0f3FC90FDA;
	fma.rn.f32 	%f67, %f65, %f66, %f146;
	mov.f32 	%f68, 0f33A22168;
	fma.rn.f32 	%f69, %f65, %f68, %f67;
	mov.f32 	%f70, 0f27C234C5;
	fma.rn.f32 	%f147, %f65, %f70, %f69;
	abs.f32 	%f71, %f146;
	setp.leu.f32	%p3, %f71, 0f47CE4780;
	@%p3 bra 	BB4_15;

	mov.b32 	 %r3, %f146;
	shr.u32 	%r4, %r3, 23;
	shl.b32 	%r92, %r3, 8;
	or.b32  	%r5, %r92, -2147483648;
	mov.u32 	%r208, 0;
	mov.u64 	%rd52, __cudart_i2opi_f;
	mov.u32 	%r207, -6;
	mov.u64 	%rd53, %rd1;

BB4_6:
	.pragma "nounroll";
	ld.const.u32 	%r95, [%rd52];
	// inline asm
	{
	mad.lo.cc.u32   %r93, %r95, %r5, %r208;
	madc.hi.u32     %r208, %r95, %r5,  0;
	}
	// inline asm
	st.local.u32 	[%rd53], %r93;
	add.s64 	%rd53, %rd53, 4;
	add.s64 	%rd52, %rd52, 4;
	add.s32 	%r207, %r207, 1;
	setp.ne.s32	%p4, %r207, 0;
	@%p4 bra 	BB4_6;

	and.b32  	%r98, %r4, 255;
	add.s32 	%r99, %r98, -128;
	shr.u32 	%r100, %r99, 5;
	and.b32  	%r10, %r3, -2147483648;
	st.local.u32 	[%rd2], %r208;
	mov.u32 	%r101, 6;
	sub.s32 	%r102, %r101, %r100;
	mul.wide.s32 	%rd17, %r102, 4;
	add.s64 	%rd9, %rd1, %rd17;
	ld.local.u32 	%r209, [%rd9];
	ld.local.u32 	%r210, [%rd9+-4];
	and.b32  	%r13, %r4, 31;
	setp.eq.s32	%p5, %r13, 0;
	@%p5 bra 	BB4_9;

	mov.u32 	%r103, 32;
	sub.s32 	%r104, %r103, %r13;
	shr.u32 	%r105, %r210, %r104;
	shl.b32 	%r106, %r209, %r13;
	add.s32 	%r209, %r105, %r106;
	ld.local.u32 	%r107, [%rd9+-8];
	shr.u32 	%r108, %r107, %r104;
	shl.b32 	%r109, %r210, %r13;
	add.s32 	%r210, %r108, %r109;

BB4_9:
	shr.u32 	%r110, %r210, 30;
	shl.b32 	%r111, %r209, 2;
	add.s32 	%r211, %r110, %r111;
	shl.b32 	%r19, %r210, 2;
	shr.u32 	%r112, %r211, 31;
	shr.u32 	%r113, %r209, 30;
	add.s32 	%r20, %r112, %r113;
	setp.eq.s32	%p6, %r112, 0;
	@%p6 bra 	BB4_10;
	bra.uni 	BB4_11;

BB4_10:
	mov.u32 	%r212, %r10;
	mov.u32 	%r213, %r19;
	bra.uni 	BB4_12;

BB4_11:
	not.b32 	%r114, %r211;
	neg.s32 	%r213, %r19;
	setp.eq.s32	%p7, %r19, 0;
	selp.u32	%r115, 1, 0, %p7;
	add.s32 	%r211, %r115, %r114;
	xor.b32  	%r212, %r10, -2147483648;

BB4_12:
	clz.b32 	%r215, %r211;
	setp.eq.s32	%p8, %r215, 0;
	shl.b32 	%r116, %r211, %r215;
	mov.u32 	%r117, 32;
	sub.s32 	%r118, %r117, %r215;
	shr.u32 	%r119, %r213, %r118;
	add.s32 	%r120, %r119, %r116;
	selp.b32	%r28, %r211, %r120, %p8;
	mov.u32 	%r121, -921707870;
	mul.hi.u32 	%r214, %r28, %r121;
	setp.eq.s32	%p9, %r10, 0;
	neg.s32 	%r122, %r20;
	selp.b32	%r216, %r20, %r122, %p9;
	setp.lt.s32	%p10, %r214, 1;
	@%p10 bra 	BB4_14;

	mul.lo.s32 	%r123, %r28, -921707870;
	shr.u32 	%r124, %r123, 31;
	shl.b32 	%r125, %r214, 1;
	add.s32 	%r214, %r124, %r125;
	add.s32 	%r215, %r215, 1;

BB4_14:
	mov.u32 	%r126, 126;
	sub.s32 	%r127, %r126, %r215;
	shl.b32 	%r128, %r127, 23;
	add.s32 	%r129, %r214, 1;
	shr.u32 	%r130, %r129, 7;
	add.s32 	%r131, %r130, 1;
	shr.u32 	%r132, %r131, 1;
	add.s32 	%r133, %r132, %r128;
	or.b32  	%r134, %r133, %r212;
	mov.b32 	 %f147, %r134;

BB4_15:
	mul.rn.f32 	%f11, %f147, %f147;
	add.s32 	%r36, %r216, 1;
	and.b32  	%r37, %r36, 1;
	setp.eq.s32	%p11, %r37, 0;
	@%p11 bra 	BB4_17;
	bra.uni 	BB4_16;

BB4_17:
	mov.f32 	%f74, 0f3C08839E;
	mov.f32 	%f75, 0fB94CA1F9;
	fma.rn.f32 	%f148, %f75, %f11, %f74;
	bra.uni 	BB4_18;

BB4_16:
	mov.f32 	%f72, 0fBAB6061A;
	mov.f32 	%f73, 0f37CCF5CE;
	fma.rn.f32 	%f148, %f73, %f11, %f72;

BB4_18:
	@%p11 bra 	BB4_20;
	bra.uni 	BB4_19;

BB4_20:
	mov.f32 	%f79, 0fBE2AAAA3;
	fma.rn.f32 	%f80, %f148, %f11, %f79;
	mov.f32 	%f81, 0f00000000;
	fma.rn.f32 	%f149, %f80, %f11, %f81;
	bra.uni 	BB4_21;

BB4_19:
	mov.f32 	%f76, 0f3D2AAAA5;
	fma.rn.f32 	%f77, %f148, %f11, %f76;
	mov.f32 	%f78, 0fBF000000;
	fma.rn.f32 	%f149, %f77, %f11, %f78;

BB4_21:
	fma.rn.f32 	%f150, %f149, %f147, %f147;
	@%p11 bra 	BB4_23;

	mov.f32 	%f82, 0f3F800000;
	fma.rn.f32 	%f150, %f149, %f11, %f82;

BB4_23:
	and.b32  	%r135, %r36, 2;
	setp.eq.s32	%p14, %r135, 0;
	@%p14 bra 	BB4_25;

	mov.f32 	%f83, 0f00000000;
	mov.f32 	%f84, 0fBF800000;
	fma.rn.f32 	%f150, %f150, %f84, %f83;

BB4_25:
	@%p2 bra 	BB4_27;

	mov.f32 	%f85, 0f00000000;
	mul.rn.f32 	%f152, %f152, %f85;

BB4_27:
	mul.f32 	%f86, %f152, 0f3F22F983;
	cvt.rni.s32.f32	%r226, %f86;
	cvt.rn.f32.s32	%f87, %r226;
	neg.f32 	%f88, %f87;
	fma.rn.f32 	%f90, %f88, %f66, %f152;
	fma.rn.f32 	%f92, %f88, %f68, %f90;
	fma.rn.f32 	%f153, %f88, %f70, %f92;
	abs.f32 	%f94, %f152;
	setp.leu.f32	%p16, %f94, 0f47CE4780;
	@%p16 bra 	BB4_38;

	mov.b32 	 %r39, %f152;
	shr.u32 	%r40, %r39, 23;
	shl.b32 	%r138, %r39, 8;
	or.b32  	%r41, %r138, -2147483648;
	mov.u32 	%r218, 0;
	mov.u64 	%rd54, __cudart_i2opi_f;
	mov.u32 	%r217, -6;
	mov.u64 	%rd55, %rd1;

BB4_29:
	.pragma "nounroll";
	ld.const.u32 	%r141, [%rd54];
	// inline asm
	{
	mad.lo.cc.u32   %r139, %r141, %r41, %r218;
	madc.hi.u32     %r218, %r141, %r41,  0;
	}
	// inline asm
	st.local.u32 	[%rd55], %r139;
	add.s64 	%rd55, %rd55, 4;
	add.s64 	%rd54, %rd54, 4;
	add.s32 	%r217, %r217, 1;
	setp.ne.s32	%p17, %r217, 0;
	@%p17 bra 	BB4_29;

	and.b32  	%r144, %r40, 255;
	add.s32 	%r145, %r144, -128;
	shr.u32 	%r146, %r145, 5;
	and.b32  	%r46, %r39, -2147483648;
	st.local.u32 	[%rd2], %r218;
	mov.u32 	%r147, 6;
	sub.s32 	%r148, %r147, %r146;
	mul.wide.s32 	%rd19, %r148, 4;
	add.s64 	%rd14, %rd1, %rd19;
	ld.local.u32 	%r219, [%rd14];
	ld.local.u32 	%r220, [%rd14+-4];
	and.b32  	%r49, %r40, 31;
	setp.eq.s32	%p18, %r49, 0;
	@%p18 bra 	BB4_32;

	mov.u32 	%r149, 32;
	sub.s32 	%r150, %r149, %r49;
	shr.u32 	%r151, %r220, %r150;
	shl.b32 	%r152, %r219, %r49;
	add.s32 	%r219, %r151, %r152;
	ld.local.u32 	%r153, [%rd14+-8];
	shr.u32 	%r154, %r153, %r150;
	shl.b32 	%r155, %r220, %r49;
	add.s32 	%r220, %r154, %r155;

BB4_32:
	shr.u32 	%r156, %r220, 30;
	shl.b32 	%r157, %r219, 2;
	add.s32 	%r221, %r156, %r157;
	shl.b32 	%r55, %r220, 2;
	shr.u32 	%r158, %r221, 31;
	shr.u32 	%r159, %r219, 30;
	add.s32 	%r56, %r158, %r159;
	setp.eq.s32	%p19, %r158, 0;
	@%p19 bra 	BB4_33;
	bra.uni 	BB4_34;

BB4_33:
	mov.u32 	%r222, %r46;
	mov.u32 	%r223, %r55;
	bra.uni 	BB4_35;

BB4_34:
	not.b32 	%r160, %r221;
	neg.s32 	%r223, %r55;
	setp.eq.s32	%p20, %r55, 0;
	selp.u32	%r161, 1, 0, %p20;
	add.s32 	%r221, %r161, %r160;
	xor.b32  	%r222, %r46, -2147483648;

BB4_35:
	clz.b32 	%r225, %r221;
	setp.eq.s32	%p21, %r225, 0;
	shl.b32 	%r162, %r221, %r225;
	mov.u32 	%r163, 32;
	sub.s32 	%r164, %r163, %r225;
	shr.u32 	%r165, %r223, %r164;
	add.s32 	%r166, %r165, %r162;
	selp.b32	%r64, %r221, %r166, %p21;
	mov.u32 	%r167, -921707870;
	mul.hi.u32 	%r224, %r64, %r167;
	setp.eq.s32	%p22, %r46, 0;
	neg.s32 	%r168, %r56;
	selp.b32	%r226, %r56, %r168, %p22;
	setp.lt.s32	%p23, %r224, 1;
	@%p23 bra 	BB4_37;

	mul.lo.s32 	%r169, %r64, -921707870;
	shr.u32 	%r170, %r169, 31;
	shl.b32 	%r171, %r224, 1;
	add.s32 	%r224, %r170, %r171;
	add.s32 	%r225, %r225, 1;

BB4_37:
	mov.u32 	%r172, 126;
	sub.s32 	%r173, %r172, %r225;
	shl.b32 	%r174, %r173, 23;
	add.s32 	%r175, %r224, 1;
	shr.u32 	%r176, %r175, 7;
	add.s32 	%r177, %r176, 1;
	shr.u32 	%r178, %r177, 1;
	add.s32 	%r179, %r178, %r174;
	or.b32  	%r180, %r179, %r222;
	mov.b32 	 %f153, %r180;

BB4_38:
	mul.rn.f32 	%f28, %f153, %f153;
	and.b32  	%r72, %r226, 1;
	setp.eq.s32	%p24, %r72, 0;
	@%p24 bra 	BB4_40;
	bra.uni 	BB4_39;

BB4_40:
	mov.f32 	%f97, 0f3C08839E;
	mov.f32 	%f98, 0fB94CA1F9;
	fma.rn.f32 	%f154, %f98, %f28, %f97;
	bra.uni 	BB4_41;

BB4_39:
	mov.f32 	%f95, 0fBAB6061A;
	mov.f32 	%f96, 0f37CCF5CE;
	fma.rn.f32 	%f154, %f96, %f28, %f95;

BB4_41:
	@%p24 bra 	BB4_43;
	bra.uni 	BB4_42;

BB4_43:
	mov.f32 	%f102, 0fBE2AAAA3;
	fma.rn.f32 	%f103, %f154, %f28, %f102;
	mov.f32 	%f104, 0f00000000;
	fma.rn.f32 	%f155, %f103, %f28, %f104;
	bra.uni 	BB4_44;

BB4_42:
	mov.f32 	%f99, 0f3D2AAAA5;
	fma.rn.f32 	%f100, %f154, %f28, %f99;
	mov.f32 	%f101, 0fBF000000;
	fma.rn.f32 	%f155, %f100, %f28, %f101;

BB4_44:
	fma.rn.f32 	%f156, %f155, %f153, %f153;
	@%p24 bra 	BB4_46;

	mov.f32 	%f105, 0f3F800000;
	fma.rn.f32 	%f156, %f155, %f28, %f105;

BB4_46:
	and.b32  	%r181, %r226, 2;
	setp.eq.s32	%p27, %r181, 0;
	@%p27 bra 	BB4_48;

	mov.f32 	%f106, 0f00000000;
	mov.f32 	%f107, 0fBF800000;
	fma.rn.f32 	%f156, %f156, %f107, %f106;

BB4_48:
	cvt.u64.u32	%rd42, %r206;
	mov.u64 	%rd44, complex;
	cvta.global.u64 	%rd21, %rd44;
	mov.u32 	%r188, 3;
	mov.u32 	%r189, 8;
	mov.u64 	%rd43, 0;
	// inline asm
	call (%rd20), _rt_buffer_get_64, (%rd21, %r188, %r189, %rd3, %rd4, %rd42, %rd43);
	// inline asm
	ld.f32 	%f108, [%rd20];
	fma.rn.f32 	%f109, %f150, %f108, %f158;
	// inline asm
	call (%rd26), _rt_buffer_get_64, (%rd21, %r188, %r189, %rd3, %rd4, %rd42, %rd43);
	// inline asm
	ld.f32 	%f110, [%rd26+4];
	mul.f32 	%f111, %f156, %f110;
	sub.f32 	%f158, %f109, %f111;
	// inline asm
	call (%rd32), _rt_buffer_get_64, (%rd21, %r188, %r189, %rd3, %rd4, %rd42, %rd43);
	// inline asm
	ld.f32 	%f112, [%rd32];
	fma.rn.f32 	%f113, %f156, %f112, %f159;
	// inline asm
	call (%rd38), _rt_buffer_get_64, (%rd21, %r188, %r189, %rd3, %rd4, %rd42, %rd43);
	// inline asm
	ld.f32 	%f114, [%rd38+4];
	fma.rn.f32 	%f159, %f150, %f114, %f113;
	add.s32 	%r206, %r206, 1;
	cvt.rn.f32.s32	%f143, %r206;
	ld.global.f32 	%f115, [fencengshu];
	setp.lt.f32	%p28, %f143, %f115;
	@%p28 bra 	BB4_2;

BB4_49:
	abs.f32 	%f45, %f158;
	setp.eq.f32	%p29, %f45, 0f00000000;
	abs.f32 	%f46, %f159;
	setp.eq.f32	%p30, %f46, 0f00000000;
	and.pred  	%p31, %p29, %p30;
	mov.b32 	 %r74, %f158;
	mov.b32 	 %r190, %f159;
	and.b32  	%r75, %r190, -2147483648;
	@%p31 bra 	BB4_53;
	bra.uni 	BB4_50;

BB4_53:
	shr.s32 	%r197, %r74, 31;
	and.b32  	%r198, %r197, 1078530011;
	or.b32  	%r199, %r198, %r75;
	mov.b32 	 %f160, %r199;
	bra.uni 	BB4_54;

BB4_50:
	setp.eq.f32	%p32, %f45, 0f7F800000;
	setp.eq.f32	%p33, %f46, 0f7F800000;
	and.pred  	%p34, %p32, %p33;
	@%p34 bra 	BB4_52;
	bra.uni 	BB4_51;

BB4_52:
	shr.s32 	%r193, %r74, 31;
	and.b32  	%r194, %r193, 13483017;
	add.s32 	%r195, %r194, 1061752795;
	or.b32  	%r196, %r195, %r75;
	mov.b32 	 %f160, %r196;
	bra.uni 	BB4_54;

BB4_51:
	max.f32 	%f116, %f46, %f45;
	min.f32 	%f117, %f46, %f45;
	div.rn.f32 	%f118, %f117, %f116;
	mul.rn.f32 	%f119, %f118, %f118;
	mov.f32 	%f120, 0fC0B59883;
	mov.f32 	%f121, 0fBF52C7EA;
	fma.rn.f32 	%f122, %f119, %f121, %f120;
	mov.f32 	%f123, 0fC0D21907;
	fma.rn.f32 	%f124, %f122, %f119, %f123;
	mul.f32 	%f125, %f119, %f124;
	mul.f32 	%f126, %f118, %f125;
	add.f32 	%f127, %f119, 0f41355DC0;
	mov.f32 	%f128, 0f41E6BD60;
	fma.rn.f32 	%f129, %f127, %f119, %f128;
	mov.f32 	%f130, 0f419D92C8;
	fma.rn.f32 	%f131, %f129, %f119, %f130;
	rcp.rn.f32 	%f132, %f131;
	fma.rn.f32 	%f133, %f126, %f132, %f118;
	mov.f32 	%f134, 0f3FC90FDB;
	sub.f32 	%f135, %f134, %f133;
	setp.gt.f32	%p35, %f46, %f45;
	selp.f32	%f136, %f135, %f133, %p35;
	mov.f32 	%f137, 0f40490FDB;
	sub.f32 	%f138, %f137, %f136;
	setp.lt.s32	%p36, %r74, 0;
	selp.f32	%f139, %f138, %f136, %p36;
	mov.b32 	 %r191, %f139;
	or.b32  	%r192, %r191, %r75;
	mov.b32 	 %f140, %r192;
	add.f32 	%f141, %f45, %f46;
	setp.gtu.f32	%p37, %f141, 0f7F800000;
	selp.f32	%f160, %f141, %f140, %p37;

BB4_54:
	setp.geu.f32	%p38, %f160, 0f00000000;
	@%p38 bra 	BB4_56;

	cvt.f64.f32	%fd12, %f160;
	add.f64 	%fd13, %fd12, 0d401921FB4D12D84A;
	cvt.rn.f32.f64	%f160, %fd13;

BB4_56:
	cvt.f64.f32	%fd14, %f160;
	mul.f64 	%fd15, %fd14, 0d3FE0000000000000;
	div.rn.f64 	%fd16, %fd15, 0d400921FB4D12D84A;
	cvt.rn.f32.f64	%f142, %fd16;
	ld.global.v2.u32 	{%r202, %r203}, [launch_index];
	cvt.u64.u32	%rd47, %r202;
	cvt.u64.u32	%rd48, %r203;
	mov.u64 	%rd51, output_buffer;
	cvta.global.u64 	%rd46, %rd51;
	mov.u32 	%r200, 2;
	mov.u32 	%r201, 4;
	mov.u64 	%rd50, 0;
	// inline asm
	call (%rd45), _rt_buffer_get_64, (%rd46, %r200, %r201, %rd47, %rd48, %rd50, %rd50);
	// inline asm
	st.f32 	[%rd45], %f142;
	ret;
}

	// .globl	_Z5holo2v
.visible .entry _Z5holo2v(

)
{
	.local .align 4 .b8 	__local_depot5[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<48>;
	.reg .f32 	%f<162>;
	.reg .b32 	%r<240>;
	.reg .f64 	%fd<17>;
	.reg .b64 	%rd<56>;


	mov.u64 	%SPL, __local_depot5;
	ld.global.v2.u32 	{%r87, %r88}, [launch_index];
	or.b32  	%r89, %r88, %r87;
	setp.lt.u32	%p1, %r89, 512;
	@%p1 bra 	BB5_5;
	bra.uni 	BB5_1;

BB5_5:
	add.s32 	%r217, %r87, 512;
	bra.uni 	BB5_6;

BB5_1:
	setp.lt.u32	%p2, %r87, 512;
	setp.gt.u32	%p3, %r88, 511;
	and.pred  	%p4, %p2, %p3;
	setp.lt.u32	%p5, %r88, 1024;
	and.pred  	%p6, %p4, %p5;
	@%p6 bra 	BB5_4;
	bra.uni 	BB5_2;

BB5_4:
	add.s32 	%r217, %r87, 512;
	add.s32 	%r218, %r88, -512;
	bra.uni 	BB5_7;

BB5_2:
	and.b32  	%r90, %r87, -512;
	setp.eq.s32	%p7, %r90, 512;
	setp.lt.u32	%p8, %r88, 512;
	and.pred  	%p9, %p7, %p8;
	add.s32 	%r217, %r87, -512;
	@%p9 bra 	BB5_6;
	bra.uni 	BB5_3;

BB5_6:
	add.s32 	%r218, %r88, 512;
	bra.uni 	BB5_7;

BB5_3:
	add.s32 	%r218, %r88, -512;

BB5_7:
	ld.global.f32 	%f55, [fencengshu];
	mov.f32 	%f158, 0f00000000;
	setp.leu.f32	%p10, %f55, 0f00000000;
	mov.f32 	%f159, %f158;
	@%p10 bra 	BB5_56;

	ld.global.v2.u32 	{%r92, %r93}, [launch_dim];
	mov.u32 	%r219, 0;
	shr.u32 	%r95, %r92, 1;
	sub.s32 	%r96, %r87, %r95;
	mul.lo.s32 	%r97, %r96, %r96;
	cvt.rn.f64.s32	%fd2, %r97;
	mul.f64 	%fd3, %fd2, 0d3F80624DD2F1A9FC;
	shr.u32 	%r99, %r93, 1;
	sub.s32 	%r100, %r88, %r99;
	cvt.rn.f64.s32	%fd4, %r100;
	mul.f64 	%fd5, %fd4, 0d3F80624DD2F1A9FC;
	mul.f64 	%fd6, %fd4, %fd5;
	mul.f64 	%fd7, %fd6, 0d3F80624DD2F1A9FC;
	fma.rn.f64 	%fd1, %fd3, 0d3F80624DD2F1A9FC, %fd7;
	add.u64 	%rd1, %SPL, 0;
	add.s64 	%rd2, %rd1, 24;
	cvt.u64.u32	%rd3, %r217;
	cvt.u64.u32	%rd4, %r218;
	mov.f32 	%f143, 0f00000000;
	mov.f32 	%f158, %f143;
	mov.f32 	%f159, %f143;

BB5_9:
	ld.global.f32 	%f59, [juli];
	ld.global.f32 	%f60, [z];
	fma.rn.f32 	%f61, %f143, %f59, %f60;
	cvt.f64.f32	%fd8, %f61;
	mov.f64 	%fd9, 0d40B3346B9BAEE9CE;
	div.rn.f64 	%fd10, %fd9, %fd8;
	mul.f64 	%fd11, %fd1, %fd10;
	cvt.rn.f32.f64	%f152, %fd11;
	abs.f32 	%f5, %f152;
	setp.neu.f32	%p11, %f5, 0f7F800000;
	mov.f32 	%f146, %f152;
	@%p11 bra 	BB5_11;

	mov.f32 	%f62, 0f00000000;
	mul.rn.f32 	%f146, %f152, %f62;

BB5_11:
	mul.f32 	%f63, %f146, 0f3F22F983;
	cvt.rni.s32.f32	%r229, %f63;
	cvt.rn.f32.s32	%f64, %r229;
	neg.f32 	%f65, %f64;
	mov.f32 	%f66, 0f3FC90FDA;
	fma.rn.f32 	%f67, %f65, %f66, %f146;
	mov.f32 	%f68, 0f33A22168;
	fma.rn.f32 	%f69, %f65, %f68, %f67;
	mov.f32 	%f70, 0f27C234C5;
	fma.rn.f32 	%f147, %f65, %f70, %f69;
	abs.f32 	%f71, %f146;
	setp.leu.f32	%p12, %f71, 0f47CE4780;
	@%p12 bra 	BB5_22;

	mov.b32 	 %r14, %f146;
	shr.u32 	%r15, %r14, 23;
	shl.b32 	%r103, %r14, 8;
	or.b32  	%r16, %r103, -2147483648;
	mov.u32 	%r221, 0;
	mov.u64 	%rd52, __cudart_i2opi_f;
	mov.u32 	%r220, -6;
	mov.u64 	%rd53, %rd1;

BB5_13:
	.pragma "nounroll";
	ld.const.u32 	%r106, [%rd52];
	// inline asm
	{
	mad.lo.cc.u32   %r104, %r106, %r16, %r221;
	madc.hi.u32     %r221, %r106, %r16,  0;
	}
	// inline asm
	st.local.u32 	[%rd53], %r104;
	add.s64 	%rd53, %rd53, 4;
	add.s64 	%rd52, %rd52, 4;
	add.s32 	%r220, %r220, 1;
	setp.ne.s32	%p13, %r220, 0;
	@%p13 bra 	BB5_13;

	and.b32  	%r109, %r15, 255;
	add.s32 	%r110, %r109, -128;
	shr.u32 	%r111, %r110, 5;
	and.b32  	%r21, %r14, -2147483648;
	st.local.u32 	[%rd2], %r221;
	mov.u32 	%r112, 6;
	sub.s32 	%r113, %r112, %r111;
	mul.wide.s32 	%rd17, %r113, 4;
	add.s64 	%rd9, %rd1, %rd17;
	ld.local.u32 	%r222, [%rd9];
	ld.local.u32 	%r223, [%rd9+-4];
	and.b32  	%r24, %r15, 31;
	setp.eq.s32	%p14, %r24, 0;
	@%p14 bra 	BB5_16;

	mov.u32 	%r114, 32;
	sub.s32 	%r115, %r114, %r24;
	shr.u32 	%r116, %r223, %r115;
	shl.b32 	%r117, %r222, %r24;
	add.s32 	%r222, %r116, %r117;
	ld.local.u32 	%r118, [%rd9+-8];
	shr.u32 	%r119, %r118, %r115;
	shl.b32 	%r120, %r223, %r24;
	add.s32 	%r223, %r119, %r120;

BB5_16:
	shr.u32 	%r121, %r223, 30;
	shl.b32 	%r122, %r222, 2;
	add.s32 	%r224, %r121, %r122;
	shl.b32 	%r30, %r223, 2;
	shr.u32 	%r123, %r224, 31;
	shr.u32 	%r124, %r222, 30;
	add.s32 	%r31, %r123, %r124;
	setp.eq.s32	%p15, %r123, 0;
	@%p15 bra 	BB5_17;
	bra.uni 	BB5_18;

BB5_17:
	mov.u32 	%r225, %r21;
	mov.u32 	%r226, %r30;
	bra.uni 	BB5_19;

BB5_18:
	not.b32 	%r125, %r224;
	neg.s32 	%r226, %r30;
	setp.eq.s32	%p16, %r30, 0;
	selp.u32	%r126, 1, 0, %p16;
	add.s32 	%r224, %r126, %r125;
	xor.b32  	%r225, %r21, -2147483648;

BB5_19:
	clz.b32 	%r228, %r224;
	setp.eq.s32	%p17, %r228, 0;
	shl.b32 	%r127, %r224, %r228;
	mov.u32 	%r128, 32;
	sub.s32 	%r129, %r128, %r228;
	shr.u32 	%r130, %r226, %r129;
	add.s32 	%r131, %r130, %r127;
	selp.b32	%r39, %r224, %r131, %p17;
	mov.u32 	%r132, -921707870;
	mul.hi.u32 	%r227, %r39, %r132;
	setp.eq.s32	%p18, %r21, 0;
	neg.s32 	%r133, %r31;
	selp.b32	%r229, %r31, %r133, %p18;
	setp.lt.s32	%p19, %r227, 1;
	@%p19 bra 	BB5_21;

	mul.lo.s32 	%r134, %r39, -921707870;
	shr.u32 	%r135, %r134, 31;
	shl.b32 	%r136, %r227, 1;
	add.s32 	%r227, %r135, %r136;
	add.s32 	%r228, %r228, 1;

BB5_21:
	mov.u32 	%r137, 126;
	sub.s32 	%r138, %r137, %r228;
	shl.b32 	%r139, %r138, 23;
	add.s32 	%r140, %r227, 1;
	shr.u32 	%r141, %r140, 7;
	add.s32 	%r142, %r141, 1;
	shr.u32 	%r143, %r142, 1;
	add.s32 	%r144, %r143, %r139;
	or.b32  	%r145, %r144, %r225;
	mov.b32 	 %f147, %r145;

BB5_22:
	mul.rn.f32 	%f11, %f147, %f147;
	add.s32 	%r47, %r229, 1;
	and.b32  	%r48, %r47, 1;
	setp.eq.s32	%p20, %r48, 0;
	@%p20 bra 	BB5_24;
	bra.uni 	BB5_23;

BB5_24:
	mov.f32 	%f74, 0f3C08839E;
	mov.f32 	%f75, 0fB94CA1F9;
	fma.rn.f32 	%f148, %f75, %f11, %f74;
	bra.uni 	BB5_25;

BB5_23:
	mov.f32 	%f72, 0fBAB6061A;
	mov.f32 	%f73, 0f37CCF5CE;
	fma.rn.f32 	%f148, %f73, %f11, %f72;

BB5_25:
	@%p20 bra 	BB5_27;
	bra.uni 	BB5_26;

BB5_27:
	mov.f32 	%f79, 0fBE2AAAA3;
	fma.rn.f32 	%f80, %f148, %f11, %f79;
	mov.f32 	%f81, 0f00000000;
	fma.rn.f32 	%f149, %f80, %f11, %f81;
	bra.uni 	BB5_28;

BB5_26:
	mov.f32 	%f76, 0f3D2AAAA5;
	fma.rn.f32 	%f77, %f148, %f11, %f76;
	mov.f32 	%f78, 0fBF000000;
	fma.rn.f32 	%f149, %f77, %f11, %f78;

BB5_28:
	fma.rn.f32 	%f150, %f149, %f147, %f147;
	@%p20 bra 	BB5_30;

	mov.f32 	%f82, 0f3F800000;
	fma.rn.f32 	%f150, %f149, %f11, %f82;

BB5_30:
	and.b32  	%r146, %r47, 2;
	setp.eq.s32	%p23, %r146, 0;
	@%p23 bra 	BB5_32;

	mov.f32 	%f83, 0f00000000;
	mov.f32 	%f84, 0fBF800000;
	fma.rn.f32 	%f150, %f150, %f84, %f83;

BB5_32:
	@%p11 bra 	BB5_34;

	mov.f32 	%f85, 0f00000000;
	mul.rn.f32 	%f152, %f152, %f85;

BB5_34:
	mul.f32 	%f86, %f152, 0f3F22F983;
	cvt.rni.s32.f32	%r239, %f86;
	cvt.rn.f32.s32	%f87, %r239;
	neg.f32 	%f88, %f87;
	fma.rn.f32 	%f90, %f88, %f66, %f152;
	fma.rn.f32 	%f92, %f88, %f68, %f90;
	fma.rn.f32 	%f153, %f88, %f70, %f92;
	abs.f32 	%f94, %f152;
	setp.leu.f32	%p25, %f94, 0f47CE4780;
	@%p25 bra 	BB5_45;

	mov.b32 	 %r50, %f152;
	shr.u32 	%r51, %r50, 23;
	shl.b32 	%r149, %r50, 8;
	or.b32  	%r52, %r149, -2147483648;
	mov.u32 	%r231, 0;
	mov.u64 	%rd54, __cudart_i2opi_f;
	mov.u32 	%r230, -6;
	mov.u64 	%rd55, %rd1;

BB5_36:
	.pragma "nounroll";
	ld.const.u32 	%r152, [%rd54];
	// inline asm
	{
	mad.lo.cc.u32   %r150, %r152, %r52, %r231;
	madc.hi.u32     %r231, %r152, %r52,  0;
	}
	// inline asm
	st.local.u32 	[%rd55], %r150;
	add.s64 	%rd55, %rd55, 4;
	add.s64 	%rd54, %rd54, 4;
	add.s32 	%r230, %r230, 1;
	setp.ne.s32	%p26, %r230, 0;
	@%p26 bra 	BB5_36;

	and.b32  	%r155, %r51, 255;
	add.s32 	%r156, %r155, -128;
	shr.u32 	%r157, %r156, 5;
	and.b32  	%r57, %r50, -2147483648;
	st.local.u32 	[%rd2], %r231;
	mov.u32 	%r158, 6;
	sub.s32 	%r159, %r158, %r157;
	mul.wide.s32 	%rd19, %r159, 4;
	add.s64 	%rd14, %rd1, %rd19;
	ld.local.u32 	%r232, [%rd14];
	ld.local.u32 	%r233, [%rd14+-4];
	and.b32  	%r60, %r51, 31;
	setp.eq.s32	%p27, %r60, 0;
	@%p27 bra 	BB5_39;

	mov.u32 	%r160, 32;
	sub.s32 	%r161, %r160, %r60;
	shr.u32 	%r162, %r233, %r161;
	shl.b32 	%r163, %r232, %r60;
	add.s32 	%r232, %r162, %r163;
	ld.local.u32 	%r164, [%rd14+-8];
	shr.u32 	%r165, %r164, %r161;
	shl.b32 	%r166, %r233, %r60;
	add.s32 	%r233, %r165, %r166;

BB5_39:
	shr.u32 	%r167, %r233, 30;
	shl.b32 	%r168, %r232, 2;
	add.s32 	%r234, %r167, %r168;
	shl.b32 	%r66, %r233, 2;
	shr.u32 	%r169, %r234, 31;
	shr.u32 	%r170, %r232, 30;
	add.s32 	%r67, %r169, %r170;
	setp.eq.s32	%p28, %r169, 0;
	@%p28 bra 	BB5_40;
	bra.uni 	BB5_41;

BB5_40:
	mov.u32 	%r235, %r57;
	mov.u32 	%r236, %r66;
	bra.uni 	BB5_42;

BB5_41:
	not.b32 	%r171, %r234;
	neg.s32 	%r236, %r66;
	setp.eq.s32	%p29, %r66, 0;
	selp.u32	%r172, 1, 0, %p29;
	add.s32 	%r234, %r172, %r171;
	xor.b32  	%r235, %r57, -2147483648;

BB5_42:
	clz.b32 	%r238, %r234;
	setp.eq.s32	%p30, %r238, 0;
	shl.b32 	%r173, %r234, %r238;
	mov.u32 	%r174, 32;
	sub.s32 	%r175, %r174, %r238;
	shr.u32 	%r176, %r236, %r175;
	add.s32 	%r177, %r176, %r173;
	selp.b32	%r75, %r234, %r177, %p30;
	mov.u32 	%r178, -921707870;
	mul.hi.u32 	%r237, %r75, %r178;
	setp.eq.s32	%p31, %r57, 0;
	neg.s32 	%r179, %r67;
	selp.b32	%r239, %r67, %r179, %p31;
	setp.lt.s32	%p32, %r237, 1;
	@%p32 bra 	BB5_44;

	mul.lo.s32 	%r180, %r75, -921707870;
	shr.u32 	%r181, %r180, 31;
	shl.b32 	%r182, %r237, 1;
	add.s32 	%r237, %r181, %r182;
	add.s32 	%r238, %r238, 1;

BB5_44:
	mov.u32 	%r183, 126;
	sub.s32 	%r184, %r183, %r238;
	shl.b32 	%r185, %r184, 23;
	add.s32 	%r186, %r237, 1;
	shr.u32 	%r187, %r186, 7;
	add.s32 	%r188, %r187, 1;
	shr.u32 	%r189, %r188, 1;
	add.s32 	%r190, %r189, %r185;
	or.b32  	%r191, %r190, %r235;
	mov.b32 	 %f153, %r191;

BB5_45:
	mul.rn.f32 	%f28, %f153, %f153;
	and.b32  	%r83, %r239, 1;
	setp.eq.s32	%p33, %r83, 0;
	@%p33 bra 	BB5_47;
	bra.uni 	BB5_46;

BB5_47:
	mov.f32 	%f97, 0f3C08839E;
	mov.f32 	%f98, 0fB94CA1F9;
	fma.rn.f32 	%f154, %f98, %f28, %f97;
	bra.uni 	BB5_48;

BB5_46:
	mov.f32 	%f95, 0fBAB6061A;
	mov.f32 	%f96, 0f37CCF5CE;
	fma.rn.f32 	%f154, %f96, %f28, %f95;

BB5_48:
	@%p33 bra 	BB5_50;
	bra.uni 	BB5_49;

BB5_50:
	mov.f32 	%f102, 0fBE2AAAA3;
	fma.rn.f32 	%f103, %f154, %f28, %f102;
	mov.f32 	%f104, 0f00000000;
	fma.rn.f32 	%f155, %f103, %f28, %f104;
	bra.uni 	BB5_51;

BB5_49:
	mov.f32 	%f99, 0f3D2AAAA5;
	fma.rn.f32 	%f100, %f154, %f28, %f99;
	mov.f32 	%f101, 0fBF000000;
	fma.rn.f32 	%f155, %f100, %f28, %f101;

BB5_51:
	fma.rn.f32 	%f156, %f155, %f153, %f153;
	@%p33 bra 	BB5_53;

	mov.f32 	%f105, 0f3F800000;
	fma.rn.f32 	%f156, %f155, %f28, %f105;

BB5_53:
	and.b32  	%r192, %r239, 2;
	setp.eq.s32	%p36, %r192, 0;
	@%p36 bra 	BB5_55;

	mov.f32 	%f106, 0f00000000;
	mov.f32 	%f107, 0fBF800000;
	fma.rn.f32 	%f156, %f156, %f107, %f106;

BB5_55:
	cvt.u64.u32	%rd42, %r219;
	mov.u64 	%rd44, complex;
	cvta.global.u64 	%rd21, %rd44;
	mov.u32 	%r199, 3;
	mov.u32 	%r200, 8;
	mov.u64 	%rd43, 0;
	// inline asm
	call (%rd20), _rt_buffer_get_64, (%rd21, %r199, %r200, %rd3, %rd4, %rd42, %rd43);
	// inline asm
	ld.f32 	%f108, [%rd20];
	fma.rn.f32 	%f109, %f150, %f108, %f158;
	// inline asm
	call (%rd26), _rt_buffer_get_64, (%rd21, %r199, %r200, %rd3, %rd4, %rd42, %rd43);
	// inline asm
	ld.f32 	%f110, [%rd26+4];
	mul.f32 	%f111, %f156, %f110;
	sub.f32 	%f158, %f109, %f111;
	// inline asm
	call (%rd32), _rt_buffer_get_64, (%rd21, %r199, %r200, %rd3, %rd4, %rd42, %rd43);
	// inline asm
	ld.f32 	%f112, [%rd32];
	fma.rn.f32 	%f113, %f156, %f112, %f159;
	// inline asm
	call (%rd38), _rt_buffer_get_64, (%rd21, %r199, %r200, %rd3, %rd4, %rd42, %rd43);
	// inline asm
	ld.f32 	%f114, [%rd38+4];
	fma.rn.f32 	%f159, %f150, %f114, %f113;
	add.s32 	%r219, %r219, 1;
	cvt.rn.f32.s32	%f143, %r219;
	ld.global.f32 	%f115, [fencengshu];
	setp.lt.f32	%p37, %f143, %f115;
	@%p37 bra 	BB5_9;

BB5_56:
	abs.f32 	%f45, %f158;
	setp.eq.f32	%p38, %f45, 0f00000000;
	abs.f32 	%f46, %f159;
	setp.eq.f32	%p39, %f46, 0f00000000;
	and.pred  	%p40, %p38, %p39;
	mov.b32 	 %r85, %f158;
	mov.b32 	 %r201, %f159;
	and.b32  	%r86, %r201, -2147483648;
	@%p40 bra 	BB5_60;
	bra.uni 	BB5_57;

BB5_60:
	shr.s32 	%r208, %r85, 31;
	and.b32  	%r209, %r208, 1078530011;
	or.b32  	%r210, %r209, %r86;
	mov.b32 	 %f160, %r210;
	bra.uni 	BB5_61;

BB5_57:
	setp.eq.f32	%p41, %f45, 0f7F800000;
	setp.eq.f32	%p42, %f46, 0f7F800000;
	and.pred  	%p43, %p41, %p42;
	@%p43 bra 	BB5_59;
	bra.uni 	BB5_58;

BB5_59:
	shr.s32 	%r204, %r85, 31;
	and.b32  	%r205, %r204, 13483017;
	add.s32 	%r206, %r205, 1061752795;
	or.b32  	%r207, %r206, %r86;
	mov.b32 	 %f160, %r207;
	bra.uni 	BB5_61;

BB5_58:
	max.f32 	%f116, %f46, %f45;
	min.f32 	%f117, %f46, %f45;
	div.rn.f32 	%f118, %f117, %f116;
	mul.rn.f32 	%f119, %f118, %f118;
	mov.f32 	%f120, 0fC0B59883;
	mov.f32 	%f121, 0fBF52C7EA;
	fma.rn.f32 	%f122, %f119, %f121, %f120;
	mov.f32 	%f123, 0fC0D21907;
	fma.rn.f32 	%f124, %f122, %f119, %f123;
	mul.f32 	%f125, %f119, %f124;
	mul.f32 	%f126, %f118, %f125;
	add.f32 	%f127, %f119, 0f41355DC0;
	mov.f32 	%f128, 0f41E6BD60;
	fma.rn.f32 	%f129, %f127, %f119, %f128;
	mov.f32 	%f130, 0f419D92C8;
	fma.rn.f32 	%f131, %f129, %f119, %f130;
	rcp.rn.f32 	%f132, %f131;
	fma.rn.f32 	%f133, %f126, %f132, %f118;
	mov.f32 	%f134, 0f3FC90FDB;
	sub.f32 	%f135, %f134, %f133;
	setp.gt.f32	%p44, %f46, %f45;
	selp.f32	%f136, %f135, %f133, %p44;
	mov.f32 	%f137, 0f40490FDB;
	sub.f32 	%f138, %f137, %f136;
	setp.lt.s32	%p45, %r85, 0;
	selp.f32	%f139, %f138, %f136, %p45;
	mov.b32 	 %r202, %f139;
	or.b32  	%r203, %r202, %r86;
	mov.b32 	 %f140, %r203;
	add.f32 	%f141, %f45, %f46;
	setp.gtu.f32	%p46, %f141, 0f7F800000;
	selp.f32	%f160, %f141, %f140, %p46;

BB5_61:
	setp.geu.f32	%p47, %f160, 0f00000000;
	@%p47 bra 	BB5_63;

	cvt.f64.f32	%fd12, %f160;
	add.f64 	%fd13, %fd12, 0d401921FB4D12D84A;
	cvt.rn.f32.f64	%f160, %fd13;

BB5_63:
	cvt.f64.f32	%fd14, %f160;
	mul.f64 	%fd15, %fd14, 0d3FE0000000000000;
	div.rn.f64 	%fd16, %fd15, 0d400921FB4D12D84A;
	cvt.rn.f32.f64	%f142, %fd16;
	ld.global.v2.u32 	{%r213, %r214}, [launch_index];
	cvt.u64.u32	%rd47, %r213;
	cvt.u64.u32	%rd48, %r214;
	mov.u64 	%rd51, output_buffer;
	cvta.global.u64 	%rd46, %rd51;
	mov.u32 	%r211, 2;
	mov.u32 	%r212, 4;
	mov.u64 	%rd50, 0;
	// inline asm
	call (%rd45), _rt_buffer_get_64, (%rd46, %r211, %r212, %rd47, %rd48, %rd50, %rd50);
	// inline asm
	st.f32 	[%rd45], %f142;
	ret;
}


